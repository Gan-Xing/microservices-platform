# ä»»åŠ¡è°ƒåº¦æœåŠ¡å¼€å‘æ–‡æ¡£ - æ ‡å‡†ç‰ˆæœ¬

## æœåŠ¡æ¦‚è¿°

ä»»åŠ¡è°ƒåº¦æœåŠ¡æ˜¯å¾®æœåŠ¡å¹³å°çš„æ ¸å¿ƒåŸºç¡€è®¾æ–½ï¼Œé¢å‘**100ç§Ÿæˆ·+10ä¸‡ç”¨æˆ·**çš„ä¼ä¸šçº§ç”Ÿäº§ç³»ç»Ÿï¼Œè´Ÿè´£å®šæ—¶ä»»åŠ¡ç®¡ç†ã€å‘¨æœŸè°ƒåº¦ã€ä»»åŠ¡æµç¼–æ’å’Œèµ„æºç®¡ç†ï¼Œä¸ºæ•´ä¸ªå¹³å°æä¾›å¯é çš„å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ã€‚

### ğŸ¯ æ ‡å‡†ç‰ˆæœ¬å®šä½
- **ä»»åŠ¡è§„æ¨¡**: æ”¯æŒ100ç§Ÿæˆ·ï¼Œæ¯å¤©æ‰§è¡Œ100ä¸‡ä¸ªå®šæ—¶ä»»åŠ¡
- **è°ƒåº¦ç²¾åº¦**: ç§’çº§è°ƒåº¦ç²¾åº¦ï¼Œæ”¯æŒå¤æ‚Cronè¡¨è¾¾å¼
- **å¯é æ€§**: 99.9%ä»»åŠ¡æ‰§è¡ŒæˆåŠŸç‡ï¼Œæ”¯æŒå¤±è´¥é‡è¯•
- **å¹¶å‘èƒ½åŠ›**: æ”¯æŒ1000ä¸ªå¹¶å‘ä»»åŠ¡æ‰§è¡Œ
- **éƒ¨ç½²æ–¹å¼**: Docker Compose + Redisåˆ†å¸ƒå¼é”

## æŠ€æœ¯æ ˆ

### åç«¯æŠ€æœ¯
- **æ¡†æ¶**: NestJS 10.x + TypeScript 5.x
- **æ•°æ®åº“**: PostgreSQL 15+ (ä»»åŠ¡å…ƒæ•°æ®) + Redis 7+ (ä»»åŠ¡é˜Ÿåˆ—)
- **ORM**: Prisma ORM
- **è°ƒåº¦å¼•æ“**: Node-cron + BullMQ
- **åˆ†å¸ƒå¼åè°ƒ**: Redis åˆ†å¸ƒå¼é”

### è°ƒåº¦æŠ€æœ¯ (æ ‡å‡†ç‰ˆæœ¬)
- **Cronè§£æ**: node-cron + cron-parser
- **é˜Ÿåˆ—ç®¡ç†**: BullMQ + Redis (é€‚åˆæ ‡å‡†ç‰ˆæœ¬)
- **ä»»åŠ¡æŒä¹…åŒ–**: PostgreSQL
- **ç›‘æ§**: Prometheus + Custom Metrics
- **æ—¥å¿—**: Winston + ç»“æ„åŒ–æ—¥å¿—

## æ ¸å¿ƒåŠŸèƒ½æ¨¡å—

### 1. ä»»åŠ¡å®šä¹‰ç®¡ç†
```typescript
// ä»»åŠ¡å®šä¹‰æ¥å£
POST   /api/v1/scheduler/jobs                    // åˆ›å»ºå®šæ—¶ä»»åŠ¡
GET    /api/v1/scheduler/jobs                    // è·å–ä»»åŠ¡åˆ—è¡¨
GET    /api/v1/scheduler/jobs/{id}               // è·å–ä»»åŠ¡è¯¦æƒ…
PUT    /api/v1/scheduler/jobs/{id}               // æ›´æ–°ä»»åŠ¡å®šä¹‰
DELETE /api/v1/scheduler/jobs/{id}               // åˆ é™¤ä»»åŠ¡
POST   /api/v1/scheduler/jobs/{id}/validate      // éªŒè¯ä»»åŠ¡é…ç½®
```

### 2. ä»»åŠ¡æ‰§è¡Œæ§åˆ¶
```typescript
// ä»»åŠ¡æ‰§è¡Œæ“ä½œ
POST   /api/v1/scheduler/jobs/{id}/trigger       // æ‰‹åŠ¨è§¦å‘ä»»åŠ¡
POST   /api/v1/scheduler/jobs/{id}/pause         // æš‚åœä»»åŠ¡
POST   /api/v1/scheduler/jobs/{id}/resume        // æ¢å¤ä»»åŠ¡
POST   /api/v1/scheduler/jobs/{id}/stop          // åœæ­¢ä»»åŠ¡
POST   /api/v1/scheduler/executions/{id}/cancel  // å–æ¶ˆæ‰§è¡Œ
```

### 3. æ‰§è¡Œå†å²æŸ¥è¯¢
```typescript
// æ‰§è¡Œå†å²ç®¡ç†
GET    /api/v1/scheduler/executions              // è·å–æ‰§è¡Œå†å²
GET    /api/v1/scheduler/executions/{id}         // è·å–æ‰§è¡Œè¯¦æƒ…
GET    /api/v1/scheduler/jobs/{id}/executions    // è·å–ä»»åŠ¡æ‰§è¡Œå†å²
GET    /api/v1/scheduler/executions/stats        // è·å–æ‰§è¡Œç»Ÿè®¡
```

### 4. è°ƒåº¦ç›‘æ§
```typescript
// è°ƒåº¦ç›‘æ§æ¥å£
GET    /api/v1/scheduler/status                  // è·å–è°ƒåº¦å™¨çŠ¶æ€
GET    /api/v1/scheduler/metrics                 // è·å–æ€§èƒ½æŒ‡æ ‡
GET    /api/v1/scheduler/queues                  // è·å–é˜Ÿåˆ—çŠ¶æ€
GET    /api/v1/scheduler/workers                 // è·å–å·¥ä½œè¿›ç¨‹çŠ¶æ€
```

## æ•°æ®åº“è®¾è®¡

### ä»»åŠ¡å®šä¹‰è¡¨ (scheduled_jobs)
```sql
CREATE TABLE scheduled_jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(200) NOT NULL,
  description TEXT,
  cron_expression VARCHAR(100) NOT NULL,
  timezone VARCHAR(50) DEFAULT 'UTC',
  job_type VARCHAR(50) NOT NULL, -- 'http', 'function', 'command'
  
  -- ä»»åŠ¡é…ç½®
  config JSONB NOT NULL, -- ä»»åŠ¡æ‰§è¡Œé…ç½®
  retry_config JSONB, -- é‡è¯•é…ç½®
  timeout_seconds INTEGER DEFAULT 300,
  max_concurrent INTEGER DEFAULT 1,
  
  -- çŠ¶æ€ç®¡ç†
  status VARCHAR(20) DEFAULT 'active', -- 'active', 'paused', 'inactive'
  priority INTEGER DEFAULT 0,
  
  -- æ‰§è¡Œé™åˆ¶
  start_date TIMESTAMP,
  end_date TIMESTAMP,
  max_executions INTEGER,
  execution_count INTEGER DEFAULT 0,
  
  -- å…ƒæ•°æ®
  tenant_id UUID NOT NULL,
  created_by UUID NOT NULL,
  tags JSONB DEFAULT '[]',
  
  -- æ—¶é—´æˆ³
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  last_execution_at TIMESTAMP,
  next_execution_at TIMESTAMP
);
```

### ä»»åŠ¡æ‰§è¡Œè¡¨ (job_executions)
```sql
CREATE TABLE job_executions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  job_id UUID REFERENCES scheduled_jobs(id) ON DELETE CASCADE,
  
  -- æ‰§è¡Œä¿¡æ¯
  execution_id VARCHAR(100) UNIQUE NOT NULL, -- BullMQ job ID
  trigger_type VARCHAR(20) NOT NULL, -- 'scheduled', 'manual', 'retry'
  triggered_by UUID,
  
  -- çŠ¶æ€è·Ÿè¸ª
  status VARCHAR(20) NOT NULL, -- 'pending', 'running', 'completed', 'failed', 'cancelled'
  progress INTEGER DEFAULT 0, -- 0-100
  
  -- æ—¶é—´è®°å½•
  scheduled_at TIMESTAMP NOT NULL,
  started_at TIMESTAMP,
  completed_at TIMESTAMP,
  duration_ms INTEGER,
  
  -- ç»“æœæ•°æ®
  result JSONB,
  error_message TEXT,
  error_stack TEXT,
  retry_count INTEGER DEFAULT 0,
  
  -- èµ„æºä½¿ç”¨
  worker_id VARCHAR(100),
  memory_peak_mb INTEGER,
  cpu_time_ms INTEGER,
  
  -- å…ƒæ•°æ®
  tenant_id UUID NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);
```

### è°ƒåº¦é”è¡¨ (scheduler_locks)
```sql
CREATE TABLE scheduler_locks (
  lock_key VARCHAR(200) PRIMARY KEY,
  locked_by VARCHAR(100) NOT NULL,
  locked_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP NOT NULL,
  metadata JSONB DEFAULT '{}'
);
```

## ä»»åŠ¡è°ƒåº¦æ¶æ„

### åˆ†å¸ƒå¼è°ƒåº¦è®¾è®¡
```mermaid
graph TB
    CronTrigger[Cronè§¦å‘å™¨] --> LockManager[åˆ†å¸ƒå¼é”ç®¡ç†å™¨]
    LockManager --> JobQueue[ä»»åŠ¡é˜Ÿåˆ—]
    JobQueue --> Worker1[WorkerèŠ‚ç‚¹1]
    JobQueue --> Worker2[WorkerèŠ‚ç‚¹2]
    JobQueue --> Worker3[WorkerèŠ‚ç‚¹N]
    
    Worker1 --> JobExecutor[ä»»åŠ¡æ‰§è¡Œå™¨]
    Worker2 --> JobExecutor
    Worker3 --> JobExecutor
    
    JobExecutor --> HTTPJob[HTTPä»»åŠ¡]
    JobExecutor --> FunctionJob[å‡½æ•°ä»»åŠ¡]
    JobExecutor --> CommandJob[å‘½ä»¤ä»»åŠ¡]
    
    JobExecutor --> ResultHandler[ç»“æœå¤„ç†å™¨]
    ResultHandler --> Database[(PostgreSQL)]
    ResultHandler --> Monitoring[ç›‘æ§ç³»ç»Ÿ]
```

### ä»»åŠ¡æ‰§è¡Œæµç¨‹
```mermaid
sequenceDiagram
    participant Cron as Cronè°ƒåº¦å™¨
    participant Lock as åˆ†å¸ƒå¼é”
    participant Queue as ä»»åŠ¡é˜Ÿåˆ—
    participant Worker as å·¥ä½œè¿›ç¨‹
    participant DB as æ•°æ®åº“
    
    Cron->>Lock: è¯·æ±‚è°ƒåº¦é”
    Lock-->>Cron: è·å–é”æˆåŠŸ
    Cron->>Queue: æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—
    Queue->>Worker: åˆ†æ´¾ä»»åŠ¡
    Worker->>DB: æ›´æ–°æ‰§è¡ŒçŠ¶æ€ä¸ºrunning
    Worker->>Worker: æ‰§è¡Œä»»åŠ¡é€»è¾‘
    Worker->>DB: ä¿å­˜æ‰§è¡Œç»“æœ
    Worker->>Queue: ç¡®è®¤ä»»åŠ¡å®Œæˆ
    Lock-->>Cron: é‡Šæ”¾è°ƒåº¦é”
```

## ä»»åŠ¡ç±»å‹è®¾è®¡

### HTTPä»»åŠ¡ç±»å‹
```typescript
interface HttpJobConfig {
  url: string;
  method: 'GET' | 'POST' | 'PUT' | 'DELETE';
  headers?: Record<string, string>;
  body?: any;
  timeout?: number;
  expectedStatusCode?: number;
  retryOnStatusCodes?: number[];
}

@Injectable()
export class HttpJobExecutor {
  async execute(config: HttpJobConfig): Promise<JobResult> {
    const response = await this.httpService.request({
      url: config.url,
      method: config.method,
      headers: config.headers,
      data: config.body,
      timeout: config.timeout || 30000
    });
    
    return {
      success: response.status === (config.expectedStatusCode || 200),
      result: response.data,
      metadata: {
        statusCode: response.status,
        headers: response.headers
      }
    };
  }
}
```

### å‡½æ•°ä»»åŠ¡ç±»å‹
```typescript
interface FunctionJobConfig {
  modulePath: string;
  functionName: string;
  parameters?: any;
  timeout?: number;
}

@Injectable()
export class FunctionJobExecutor {
  async execute(config: FunctionJobConfig): Promise<JobResult> {
    const module = await import(config.modulePath);
    const func = module[config.functionName];
    
    if (typeof func !== 'function') {
      throw new Error(`Function ${config.functionName} not found`);
    }
    
    const result = await Promise.race([
      func(config.parameters),
      this.createTimeout(config.timeout || 300000)
    ]);
    
    return {
      success: true,
      result: result
    };
  }
}
```

### å‘½ä»¤ä»»åŠ¡ç±»å‹
```typescript
interface CommandJobConfig {
  command: string;
  args?: string[];
  workingDirectory?: string;
  environment?: Record<string, string>;
  timeout?: number;
}

@Injectable()
export class CommandJobExecutor {
  async execute(config: CommandJobConfig): Promise<JobResult> {
    const child = spawn(config.command, config.args, {
      cwd: config.workingDirectory,
      env: { ...process.env, ...config.environment },
      stdio: 'pipe'
    });
    
    const result = await this.waitForCompletion(child, config.timeout);
    
    return {
      success: result.exitCode === 0,
      result: {
        stdout: result.stdout,
        stderr: result.stderr,
        exitCode: result.exitCode
      }
    };
  }
}
```

## Cronè¡¨è¾¾å¼è§£æ

### è¡¨è¾¾å¼æ ¼å¼æ”¯æŒ
```typescript
// æ ‡å‡†Cronæ ¼å¼: ç§’ åˆ† æ—¶ æ—¥ æœˆ å‘¨
// ç¤ºä¾‹è¡¨è¾¾å¼
const examples = [
  '0 */5 * * * *',      // æ¯5åˆ†é’Ÿæ‰§è¡Œ
  '0 0 2 * * *',        // æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
  '0 0 9 * * 1-5',      // å·¥ä½œæ—¥ä¸Šåˆ9ç‚¹æ‰§è¡Œ
  '0 0/30 9-17 * * *',  // å·¥ä½œæ—¶é—´æ¯30åˆ†é’Ÿæ‰§è¡Œ
  '0 0 0 1 * *',        // æ¯æœˆ1å·åˆå¤œæ‰§è¡Œ
];

@Injectable()
export class CronParser {
  parseExpression(expression: string): CronTime {
    const parsed = cronParser.parseExpression(expression);
    return {
      next: () => parsed.next().toDate(),
      prev: () => parsed.prev().toDate(),
      hasNext: () => parsed.hasNext(),
      iterate: (count: number) => 
        Array.from({ length: count }, () => parsed.next().toDate())
    };
  }
  
  validateExpression(expression: string): boolean {
    try {
      cronParser.parseExpression(expression);
      return true;
    } catch {
      return false;
    }
  }
}
```

### æ—¶åŒºå¤„ç†
```typescript
@Injectable()
export class TimezoneHandler {
  convertToTimezone(date: Date, timezone: string): Date {
    return new Date(date.toLocaleString('en-US', { timeZone: timezone }));
  }
  
  getNextExecution(cronExpression: string, timezone: string): Date {
    const parser = cronParser.parseExpression(cronExpression, {
      tz: timezone
    });
    return parser.next().toDate();
  }
}
```

## é‡è¯•å’Œé”™è¯¯å¤„ç†

### é‡è¯•ç­–ç•¥é…ç½®
```typescript
interface RetryConfig {
  maxRetries: number;
  retryDelayMs: number;
  exponentialBackoff: boolean;
  retryOnErrorTypes?: string[];
  maxRetryDelayMs?: number;
}

@Injectable()
export class RetryManager {
  async executeWithRetry<T>(
    job: () => Promise<T>,
    config: RetryConfig
  ): Promise<T> {
    let lastError: Error;
    
    for (let attempt = 0; attempt <= config.maxRetries; attempt++) {
      try {
        return await job();
      } catch (error) {
        lastError = error;
        
        if (attempt === config.maxRetries) {
          break;
        }
        
        if (!this.shouldRetry(error, config)) {
          throw error;
        }
        
        const delay = this.calculateDelay(attempt, config);
        await this.delay(delay);
      }
    }
    
    throw lastError;
  }
  
  private calculateDelay(attempt: number, config: RetryConfig): number {
    let delay = config.retryDelayMs;
    
    if (config.exponentialBackoff) {
      delay *= Math.pow(2, attempt);
    }
    
    return Math.min(delay, config.maxRetryDelayMs || Infinity);
  }
}
```

### é”™è¯¯åˆ†ç±»å¤„ç†
```typescript
enum JobErrorType {
  TIMEOUT = 'TIMEOUT',
  NETWORK_ERROR = 'NETWORK_ERROR',
  VALIDATION_ERROR = 'VALIDATION_ERROR',
  SYSTEM_ERROR = 'SYSTEM_ERROR',
  USER_ERROR = 'USER_ERROR'
}

@Injectable()
export class ErrorClassifier {
  classifyError(error: Error): JobErrorType {
    if (error.name === 'TimeoutError') {
      return JobErrorType.TIMEOUT;
    }
    
    if (error.message.includes('ECONNREFUSED')) {
      return JobErrorType.NETWORK_ERROR;
    }
    
    // å…¶ä»–åˆ†ç±»é€»è¾‘
    return JobErrorType.SYSTEM_ERROR;
  }
  
  shouldRetry(errorType: JobErrorType): boolean {
    const retryableErrors = [
      JobErrorType.TIMEOUT,
      JobErrorType.NETWORK_ERROR,
      JobErrorType.SYSTEM_ERROR
    ];
    
    return retryableErrors.includes(errorType);
  }
}
```

## åˆ†å¸ƒå¼é”å®ç°

### Redisåˆ†å¸ƒå¼é”
```typescript
@Injectable()
export class DistributedLockService {
  constructor(private readonly redis: Redis) {}
  
  async acquireLock(
    key: string, 
    ttlMs: number = 30000,
    identifier?: string
  ): Promise<string | null> {
    const lockId = identifier || uuidv4();
    const lockKey = `lock:${key}`;
    
    const result = await this.redis.set(
      lockKey, 
      lockId, 
      'PX', 
      ttlMs, 
      'NX'
    );
    
    return result === 'OK' ? lockId : null;
  }
  
  async releaseLock(key: string, lockId: string): Promise<boolean> {
    const script = `
      if redis.call("GET", KEYS[1]) == ARGV[1] then
        return redis.call("DEL", KEYS[1])
      else
        return 0
      end
    `;
    
    const result = await this.redis.eval(
      script, 
      1, 
      `lock:${key}`, 
      lockId
    );
    
    return result === 1;
  }
  
  async extendLock(key: string, lockId: string, ttlMs: number): Promise<boolean> {
    const script = `
      if redis.call("GET", KEYS[1]) == ARGV[1] then
        return redis.call("PEXPIRE", KEYS[1], ARGV[2])
      else
        return 0
      end
    `;
    
    const result = await this.redis.eval(
      script,
      1,
      `lock:${key}`,
      lockId,
      ttlMs.toString()
    );
    
    return result === 1;
  }
}
```

### è°ƒåº¦é”ç®¡ç†
```typescript
@Injectable()
export class SchedulerLockManager {
  async withLock<T>(
    jobId: string,
    operation: () => Promise<T>,
    ttlMs: number = 30000
  ): Promise<T> {
    const lockKey = `scheduler:job:${jobId}`;
    const lockId = await this.lockService.acquireLock(lockKey, ttlMs);
    
    if (!lockId) {
      throw new Error(`Failed to acquire lock for job ${jobId}`);
    }
    
    try {
      return await operation();
    } finally {
      await this.lockService.releaseLock(lockKey, lockId);
    }
  }
}
```

## ç›‘æ§æŒ‡æ ‡

### ä¸šåŠ¡æŒ‡æ ‡
```typescript
interface SchedulerMetrics {
  // ä»»åŠ¡ç»Ÿè®¡
  totalJobs: number;
  activeJobs: number;
  pausedJobs: number;
  
  // æ‰§è¡Œç»Ÿè®¡
  totalExecutions: number;
  successfulExecutions: number;
  failedExecutions: number;
  cancelledExecutions: number;
  
  // æ€§èƒ½æŒ‡æ ‡
  averageExecutionTime: number;
  queueLength: number;
  activeWorkers: number;
  
  // é”™è¯¯ç‡
  errorRate: number;
  timeoutRate: number;
  retryRate: number;
}

@Injectable()
export class MetricsCollector {
  @Cron('*/30 * * * * *') // æ¯30ç§’æ”¶é›†ä¸€æ¬¡
  async collectMetrics(): Promise<void> {
    const metrics = await this.calculateMetrics();
    
    // å‘é€åˆ°ç›‘æ§ç³»ç»Ÿ
    this.prometheusService.setGauge('scheduler_total_jobs', metrics.totalJobs);
    this.prometheusService.setGauge('scheduler_queue_length', metrics.queueLength);
    this.prometheusService.setGauge('scheduler_error_rate', metrics.errorRate);
    
    // å‘é€åˆ°æ•°æ®åº“
    await this.metricsRepository.save(metrics);
  }
}
```

### æ€§èƒ½ç›‘æ§
```typescript
// PrometheusæŒ‡æ ‡å®šä¹‰
const schedulerMetrics = {
  jobExecutions: new Counter({
    name: 'scheduler_job_executions_total',
    help: 'Total number of job executions',
    labelNames: ['job_type', 'status', 'tenant_id']
  }),
  
  executionDuration: new Histogram({
    name: 'scheduler_execution_duration_seconds',
    help: 'Job execution duration in seconds',
    labelNames: ['job_type', 'tenant_id'],
    buckets: [0.1, 0.5, 1, 5, 10, 30, 60, 300]
  }),
  
  queueSize: new Gauge({
    name: 'scheduler_queue_size',
    help: 'Current size of job queue',
    labelNames: ['queue_name']
  })
};
```

## APIè®¾è®¡è§„èŒƒ

### ä»»åŠ¡åˆ›å»ºè¯·æ±‚
```typescript
interface CreateJobRequest {
  name: string;
  description?: string;
  cronExpression: string;
  timezone?: string;
  jobType: 'http' | 'function' | 'command';
  config: HttpJobConfig | FunctionJobConfig | CommandJobConfig;
  retryConfig?: RetryConfig;
  timeout?: number;
  priority?: number;
  startDate?: string;
  endDate?: string;
  maxExecutions?: number;
  tags?: string[];
}

interface JobResponse {
  id: string;
  name: string;
  status: 'active' | 'paused' | 'inactive';
  cronExpression: string;
  nextExecutionAt: string;
  lastExecutionAt?: string;
  executionCount: number;
  createdAt: string;
  updatedAt: string;
}
```

### é”™è¯¯å“åº”æ ¼å¼
```typescript
enum SchedulerErrorCode {
  INVALID_CRON_EXPRESSION = 'INVALID_CRON_EXPRESSION',
  JOB_NOT_FOUND = 'JOB_NOT_FOUND',
  JOB_ALREADY_RUNNING = 'JOB_ALREADY_RUNNING',
  INVALID_JOB_CONFIG = 'INVALID_JOB_CONFIG',
  LOCK_ACQUISITION_FAILED = 'LOCK_ACQUISITION_FAILED',
  QUOTA_EXCEEDED = 'QUOTA_EXCEEDED'
}

interface SchedulerErrorResponse {
  error: {
    code: SchedulerErrorCode;
    message: string;
    details?: any;
  };
  timestamp: string;
  path: string;
}
```

## éƒ¨ç½²é…ç½®

### ç¯å¢ƒå˜é‡
```env
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://user:password@localhost:5432/scheduler
REDIS_URL=redis://localhost:6379

# è°ƒåº¦é…ç½®
SCHEDULER_WORKER_COUNT=5
SCHEDULER_MAX_CONCURRENT_JOBS=100
SCHEDULER_JOB_TIMEOUT_MS=300000
SCHEDULER_LOCK_TTL_MS=30000

# é˜Ÿåˆ—é…ç½®
BULL_REDIS_HOST=localhost
BULL_REDIS_PORT=6379
BULL_REDIS_DB=1

# ç›‘æ§é…ç½®
METRICS_ENABLED=true
PROMETHEUS_PORT=9464
LOG_LEVEL=info
```

### Dockeré…ç½®
```dockerfile
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY dist/ ./dist/

EXPOSE 3009 9464

CMD ["node", "dist/main.js"]
```

## æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•
```typescript
describe('CronParser', () => {
  it('should parse valid cron expression', () => {
    const parser = new CronParser();
    const result = parser.parseExpression('0 */5 * * * *');
    expect(result).toBeDefined();
  });
  
  it('should reject invalid cron expression', () => {
    const parser = new CronParser();
    expect(() => parser.parseExpression('invalid')).toThrow();
  });
});

describe('DistributedLockService', () => {
  it('should acquire and release lock successfully', async () => {
    const lockId = await lockService.acquireLock('test-key', 5000);
    expect(lockId).toBeTruthy();
    
    const released = await lockService.releaseLock('test-key', lockId);
    expect(released).toBe(true);
  });
});
```

### é›†æˆæµ‹è¯•
```typescript
describe('Job Execution', () => {
  it('should execute HTTP job successfully', async () => {
    const job = await createTestJob({
      type: 'http',
      config: {
        url: 'https://httpbin.org/get',
        method: 'GET'
      }
    });
    
    const execution = await triggerJob(job.id);
    await waitForCompletion(execution.id);
    
    const result = await getExecution(execution.id);
    expect(result.status).toBe('completed');
    expect(result.result.success).toBe(true);
  });
});
```

## æ€§èƒ½ä¼˜åŒ–

### æ•°æ®åº“ä¼˜åŒ–
```sql
-- å…³é”®ç´¢å¼•
CREATE INDEX idx_scheduled_jobs_next_execution ON scheduled_jobs(next_execution_at) WHERE status = 'active';
CREATE INDEX idx_job_executions_job_id_created ON job_executions(job_id, created_at DESC);
CREATE INDEX idx_job_executions_status_tenant ON job_executions(status, tenant_id);

-- åˆ†åŒºè¡¨ï¼ˆæŒ‰æœˆåˆ†åŒºï¼‰
CREATE TABLE job_executions_y2024m01 PARTITION OF job_executions
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

### ç¼“å­˜ç­–ç•¥
```typescript
// ä»»åŠ¡é…ç½®ç¼“å­˜
Cache Key: scheduler:job_config:{jobId}
TTL: 1å°æ—¶

// æ‰§è¡Œç»Ÿè®¡ç¼“å­˜
Cache Key: scheduler:stats:{tenantId}:{date}
TTL: 24å°æ—¶

// ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´ç¼“å­˜
Cache Key: scheduler:next_execution:{jobId}
TTL: æ ¹æ®ä»»åŠ¡é¢‘ç‡åŠ¨æ€è®¾ç½®
```

## å®‰å…¨è€ƒè™‘

### ä»»åŠ¡éš”ç¦»
- ç§Ÿæˆ·çº§åˆ«çš„ä»»åŠ¡éš”ç¦»
- èµ„æºä½¿ç”¨é™åˆ¶
- æ‰§è¡Œæ—¶é—´é™åˆ¶
- å¹¶å‘æ•°é™åˆ¶

### æƒé™æ§åˆ¶
- ä»»åŠ¡åˆ›å»ºæƒé™éªŒè¯
- æ‰§è¡Œç»“æœè®¿é—®æ§åˆ¶
- æ•æ„Ÿé…ç½®åŠ å¯†å­˜å‚¨
- å®¡è®¡æ—¥å¿—è®°å½•

é€šè¿‡è¿™æ ·çš„è®¾è®¡ï¼Œä»»åŠ¡è°ƒåº¦æœåŠ¡èƒ½å¤Ÿæä¾›å¯é ã€é«˜æ€§èƒ½ã€å¯æ‰©å±•çš„å®šæ—¶ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ï¼Œæ»¡è¶³ä¼ä¸šçº§åº”ç”¨çš„å„ç§è°ƒåº¦éœ€æ±‚ã€‚