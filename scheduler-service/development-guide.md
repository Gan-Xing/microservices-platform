# ä»»åŠ¡è°ƒåº¦æœåŠ¡å¼€å‘æ–‡æ¡£ - æ ‡å‡†ç‰ˆæœ¬

## æœåŠ¡æ¦‚è¿°

ä»»åŠ¡è°ƒåº¦æœåŠ¡æ˜¯å¾®æœåŠ¡å¹³å°çš„æ ¸å¿ƒåŸºç¡€è®¾æ–½ï¼Œé¢å‘**100ç§Ÿæˆ·+10ä¸‡ç”¨æˆ·**çš„ä¼ä¸šçº§ç”Ÿäº§ç³»ç»Ÿï¼Œè´Ÿè´£å®šæ—¶ä»»åŠ¡ç®¡ç†ã€å‘¨æœŸè°ƒåº¦ã€ä»»åŠ¡æµç¼–æ’å’Œèµ„æºç®¡ç†ï¼Œä¸ºæ•´ä¸ªå¹³å°æä¾›å¯é çš„å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ã€‚

### ğŸ¯ æ ‡å‡†ç‰ˆæœ¬å®šä½
- **ä»»åŠ¡è§„æ¨¡**: æ”¯æŒ100ç§Ÿæˆ·ï¼Œæ¯å¤©æ‰§è¡Œ100ä¸‡ä¸ªå®šæ—¶ä»»åŠ¡
- **è°ƒåº¦ç²¾åº¦**: ç§’çº§è°ƒåº¦ç²¾åº¦ï¼Œæ”¯æŒå¤æ‚Cronè¡¨è¾¾å¼
- **å¯é æ€§**: 99.9%ä»»åŠ¡æ‰§è¡ŒæˆåŠŸç‡ï¼Œæ”¯æŒå¤±è´¥é‡è¯•
- **å¹¶å‘èƒ½åŠ›**: æ”¯æŒ1000ä¸ªå¹¶å‘ä»»åŠ¡æ‰§è¡Œ
- **éƒ¨ç½²æ–¹å¼**: Docker Compose + Redisåˆ†å¸ƒå¼é”

## æŠ€æœ¯æ ˆ

### åç«¯æŠ€æœ¯
- **æ¡†æ¶**: NestJS 10.x + TypeScript 5.x
- **æ•°æ®åº“**: PostgreSQL 15+ (ä»»åŠ¡å…ƒæ•°æ®) + Redis 7+ (ä»»åŠ¡é˜Ÿåˆ—)
- **ORM**: Prisma ORM
- **è°ƒåº¦å¼•æ“**: Node-cron + BullMQ
- **åˆ†å¸ƒå¼åè°ƒ**: Redis åˆ†å¸ƒå¼é”

### è°ƒåº¦æŠ€æœ¯ (æ ‡å‡†ç‰ˆæœ¬)
- **Cronè§£æ**: node-cron + cron-parser
- **é˜Ÿåˆ—ç®¡ç†**: BullMQ + Redis (é€‚åˆæ ‡å‡†ç‰ˆæœ¬)
- **ä»»åŠ¡æŒä¹…åŒ–**: PostgreSQL
- **ç›‘æ§**: Prometheus + Custom Metrics
- **æ—¥å¿—**: Winston + ç»“æ„åŒ–æ—¥å¿—

## æ ¸å¿ƒåŠŸèƒ½æ¨¡å—

### 1. ä»»åŠ¡å®šä¹‰ç®¡ç†
```typescript
// ä»»åŠ¡å®šä¹‰æ¥å£
POST   /api/v1/scheduler/jobs                    // åˆ›å»ºå®šæ—¶ä»»åŠ¡
GET    /api/v1/scheduler/jobs                    // è·å–ä»»åŠ¡åˆ—è¡¨
GET    /api/v1/scheduler/jobs/{id}               // è·å–ä»»åŠ¡è¯¦æƒ…
PUT    /api/v1/scheduler/jobs/{id}               // æ›´æ–°ä»»åŠ¡å®šä¹‰
DELETE /api/v1/scheduler/jobs/{id}               // åˆ é™¤ä»»åŠ¡
POST   /api/v1/scheduler/jobs/{id}/validate      // éªŒè¯ä»»åŠ¡é…ç½®
```

### 2. ä»»åŠ¡æ‰§è¡Œæ§åˆ¶
```typescript
// ä»»åŠ¡æ‰§è¡Œæ“ä½œ
POST   /api/v1/scheduler/jobs/{id}/trigger       // æ‰‹åŠ¨è§¦å‘ä»»åŠ¡
POST   /api/v1/scheduler/jobs/{id}/pause         // æš‚åœä»»åŠ¡
POST   /api/v1/scheduler/jobs/{id}/resume        // æ¢å¤ä»»åŠ¡
POST   /api/v1/scheduler/jobs/{id}/stop          // åœæ­¢ä»»åŠ¡
POST   /api/v1/scheduler/executions/{id}/cancel  // å–æ¶ˆæ‰§è¡Œ
```

### 3. æ‰§è¡Œå†å²æŸ¥è¯¢
```typescript
// æ‰§è¡Œå†å²ç®¡ç†
GET    /api/v1/scheduler/executions              // è·å–æ‰§è¡Œå†å²
GET    /api/v1/scheduler/executions/{id}         // è·å–æ‰§è¡Œè¯¦æƒ…
GET    /api/v1/scheduler/jobs/{id}/executions    // è·å–ä»»åŠ¡æ‰§è¡Œå†å²
GET    /api/v1/scheduler/executions/stats        // è·å–æ‰§è¡Œç»Ÿè®¡
```

### 4. è°ƒåº¦ç›‘æ§
```typescript
// è°ƒåº¦ç›‘æ§æ¥å£
GET    /api/v1/scheduler/status                  // è·å–è°ƒåº¦å™¨çŠ¶æ€
GET    /api/v1/scheduler/metrics                 // è·å–æ€§èƒ½æŒ‡æ ‡
GET    /api/v1/scheduler/queues                  // è·å–é˜Ÿåˆ—çŠ¶æ€
GET    /api/v1/scheduler/workers                 // è·å–å·¥ä½œè¿›ç¨‹çŠ¶æ€
```

## æ•°æ®åº“è®¾è®¡

### ä»»åŠ¡å®šä¹‰è¡¨ (scheduled_jobs)
```sql
CREATE TABLE scheduled_jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(200) NOT NULL,
  description TEXT,
  cron_expression VARCHAR(100) NOT NULL,
  timezone VARCHAR(50) DEFAULT 'UTC',
  job_type VARCHAR(50) NOT NULL, -- 'http', 'function', 'command'
  
  -- ä»»åŠ¡é…ç½®
  config JSONB NOT NULL, -- ä»»åŠ¡æ‰§è¡Œé…ç½®
  retry_config JSONB, -- é‡è¯•é…ç½®
  timeout_seconds INTEGER DEFAULT 300,
  max_concurrent INTEGER DEFAULT 1,
  
  -- çŠ¶æ€ç®¡ç†
  status VARCHAR(20) DEFAULT 'active', -- 'active', 'paused', 'inactive'
  priority INTEGER DEFAULT 0,
  
  -- æ‰§è¡Œé™åˆ¶
  start_date TIMESTAMP,
  end_date TIMESTAMP,
  max_executions INTEGER,
  execution_count INTEGER DEFAULT 0,
  
  -- å…ƒæ•°æ®
  tenant_id UUID NOT NULL,
  created_by UUID NOT NULL,
  tags JSONB DEFAULT '[]',
  
  -- æ—¶é—´æˆ³
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  last_execution_at TIMESTAMP,
  next_execution_at TIMESTAMP
);
```

### ä»»åŠ¡æ‰§è¡Œè¡¨ (job_executions)
```sql
CREATE TABLE job_executions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  job_id UUID REFERENCES scheduled_jobs(id) ON DELETE CASCADE,
  
  -- æ‰§è¡Œä¿¡æ¯
  execution_id VARCHAR(100) UNIQUE NOT NULL, -- BullMQ job ID
  trigger_type VARCHAR(20) NOT NULL, -- 'scheduled', 'manual', 'retry'
  triggered_by UUID,
  
  -- çŠ¶æ€è·Ÿè¸ª
  status VARCHAR(20) NOT NULL, -- 'pending', 'running', 'completed', 'failed', 'cancelled'
  progress INTEGER DEFAULT 0, -- 0-100
  
  -- æ—¶é—´è®°å½•
  scheduled_at TIMESTAMP NOT NULL,
  started_at TIMESTAMP,
  completed_at TIMESTAMP,
  duration_ms INTEGER,
  
  -- ç»“æœæ•°æ®
  result JSONB,
  error_message TEXT,
  error_stack TEXT,
  retry_count INTEGER DEFAULT 0,
  
  -- èµ„æºä½¿ç”¨
  worker_id VARCHAR(100),
  memory_peak_mb INTEGER,
  cpu_time_ms INTEGER,
  
  -- å…ƒæ•°æ®
  tenant_id UUID NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);
```

### è°ƒåº¦é”è¡¨ (scheduler_locks)
```sql
CREATE TABLE scheduler_locks (
  lock_key VARCHAR(200) PRIMARY KEY,
  locked_by VARCHAR(100) NOT NULL,
  locked_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP NOT NULL,
  metadata JSONB DEFAULT '{}'
);
```

## ä»»åŠ¡è°ƒåº¦æ¶æ„

### åˆ†å¸ƒå¼è°ƒåº¦è®¾è®¡
```mermaid
graph TB
    CronTrigger[Cronè§¦å‘å™¨] --> LockManager[åˆ†å¸ƒå¼é”ç®¡ç†å™¨]
    LockManager --> JobQueue[ä»»åŠ¡é˜Ÿåˆ—]
    JobQueue --> Worker1[WorkerèŠ‚ç‚¹1]
    JobQueue --> Worker2[WorkerèŠ‚ç‚¹2]
    JobQueue --> Worker3[WorkerèŠ‚ç‚¹N]
    
    Worker1 --> JobExecutor[ä»»åŠ¡æ‰§è¡Œå™¨]
    Worker2 --> JobExecutor
    Worker3 --> JobExecutor
    
    JobExecutor --> HTTPJob[HTTPä»»åŠ¡]
    JobExecutor --> FunctionJob[å‡½æ•°ä»»åŠ¡]
    JobExecutor --> CommandJob[å‘½ä»¤ä»»åŠ¡]
    
    JobExecutor --> ResultHandler[ç»“æœå¤„ç†å™¨]
    ResultHandler --> Database[(PostgreSQL)]
    ResultHandler --> Monitoring[ç›‘æ§ç³»ç»Ÿ]
```

### ä»»åŠ¡æ‰§è¡Œæµç¨‹
```mermaid
sequenceDiagram
    participant Cron as Cronè°ƒåº¦å™¨
    participant Lock as åˆ†å¸ƒå¼é”
    participant Queue as ä»»åŠ¡é˜Ÿåˆ—
    participant Worker as å·¥ä½œè¿›ç¨‹
    participant DB as æ•°æ®åº“
    
    Cron->>Lock: è¯·æ±‚è°ƒåº¦é”
    Lock-->>Cron: è·å–é”æˆåŠŸ
    Cron->>Queue: æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—
    Queue->>Worker: åˆ†æ´¾ä»»åŠ¡
    Worker->>DB: æ›´æ–°æ‰§è¡ŒçŠ¶æ€ä¸ºrunning
    Worker->>Worker: æ‰§è¡Œä»»åŠ¡é€»è¾‘
    Worker->>DB: ä¿å­˜æ‰§è¡Œç»“æœ
    Worker->>Queue: ç¡®è®¤ä»»åŠ¡å®Œæˆ
    Lock-->>Cron: é‡Šæ”¾è°ƒåº¦é”
```

## ä»»åŠ¡ç±»å‹è®¾è®¡

### HTTPä»»åŠ¡ç±»å‹
```typescript
interface HttpJobConfig {
  url: string;
  method: 'GET' | 'POST' | 'PUT' | 'DELETE';
  headers?: Record<string, string>;
  body?: any;
  timeout?: number;
  expectedStatusCode?: number;
  retryOnStatusCodes?: number[];
}

@Injectable()
export class HttpJobExecutor {
  async execute(config: HttpJobConfig): Promise<JobResult> {
    const response = await this.httpService.request({
      url: config.url,
      method: config.method,
      headers: config.headers,
      data: config.body,
      timeout: config.timeout || 30000
    });
    
    return {
      success: response.status === (config.expectedStatusCode || 200),
      result: response.data,
      metadata: {
        statusCode: response.status,
        headers: response.headers
      }
    };
  }
}
```

### å‡½æ•°ä»»åŠ¡ç±»å‹
```typescript
interface FunctionJobConfig {
  modulePath: string;
  functionName: string;
  parameters?: any;
  timeout?: number;
}

@Injectable()
export class FunctionJobExecutor {
  async execute(config: FunctionJobConfig): Promise<JobResult> {
    const module = await import(config.modulePath);
    const func = module[config.functionName];
    
    if (typeof func !== 'function') {
      throw new Error(`Function ${config.functionName} not found`);
    }
    
    const result = await Promise.race([
      func(config.parameters),
      this.createTimeout(config.timeout || 300000)
    ]);
    
    return {
      success: true,
      result: result
    };
  }
}
```

### å‘½ä»¤ä»»åŠ¡ç±»å‹
```typescript
interface CommandJobConfig {
  command: string;
  args?: string[];
  workingDirectory?: string;
  environment?: Record<string, string>;
  timeout?: number;
}

@Injectable()
export class CommandJobExecutor {
  async execute(config: CommandJobConfig): Promise<JobResult> {
    const child = spawn(config.command, config.args, {
      cwd: config.workingDirectory,
      env: { ...process.env, ...config.environment },
      stdio: 'pipe'
    });
    
    const result = await this.waitForCompletion(child, config.timeout);
    
    return {
      success: result.exitCode === 0,
      result: {
        stdout: result.stdout,
        stderr: result.stderr,
        exitCode: result.exitCode
      }
    };
  }
}
```

## Cronè¡¨è¾¾å¼è§£æ

### è¡¨è¾¾å¼æ ¼å¼æ”¯æŒ
```typescript
// æ ‡å‡†Cronæ ¼å¼: ç§’ åˆ† æ—¶ æ—¥ æœˆ å‘¨
// ç¤ºä¾‹è¡¨è¾¾å¼
const examples = [
  '0 */5 * * * *',      // æ¯5åˆ†é’Ÿæ‰§è¡Œ
  '0 0 2 * * *',        // æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
  '0 0 9 * * 1-5',      // å·¥ä½œæ—¥ä¸Šåˆ9ç‚¹æ‰§è¡Œ
  '0 0/30 9-17 * * *',  // å·¥ä½œæ—¶é—´æ¯30åˆ†é’Ÿæ‰§è¡Œ
  '0 0 0 1 * *',        // æ¯æœˆ1å·åˆå¤œæ‰§è¡Œ
];

@Injectable()
export class CronParser {
  parseExpression(expression: string): CronTime {
    const parsed = cronParser.parseExpression(expression);
    return {
      next: () => parsed.next().toDate(),
      prev: () => parsed.prev().toDate(),
      hasNext: () => parsed.hasNext(),
      iterate: (count: number) => 
        Array.from({ length: count }, () => parsed.next().toDate())
    };
  }
  
  validateExpression(expression: string): boolean {
    try {
      cronParser.parseExpression(expression);
      return true;
    } catch {
      return false;
    }
  }
}
```

### æ—¶åŒºå¤„ç†
```typescript
@Injectable()
export class TimezoneHandler {
  convertToTimezone(date: Date, timezone: string): Date {
    return new Date(date.toLocaleString('en-US', { timeZone: timezone }));
  }
  
  getNextExecution(cronExpression: string, timezone: string): Date {
    const parser = cronParser.parseExpression(cronExpression, {
      tz: timezone
    });
    return parser.next().toDate();
  }
}
```

## é‡è¯•å’Œé”™è¯¯å¤„ç†

### é‡è¯•ç­–ç•¥é…ç½®
```typescript
interface RetryConfig {
  maxRetries: number;
  retryDelayMs: number;
  exponentialBackoff: boolean;
  retryOnErrorTypes?: string[];
  maxRetryDelayMs?: number;
}

@Injectable()
export class RetryManager {
  async executeWithRetry<T>(
    job: () => Promise<T>,
    config: RetryConfig
  ): Promise<T> {
    let lastError: Error;
    
    for (let attempt = 0; attempt <= config.maxRetries; attempt++) {
      try {
        return await job();
      } catch (error) {
        lastError = error;
        
        if (attempt === config.maxRetries) {
          break;
        }
        
        if (!this.shouldRetry(error, config)) {
          throw error;
        }
        
        const delay = this.calculateDelay(attempt, config);
        await this.delay(delay);
      }
    }
    
    throw lastError;
  }
  
  private calculateDelay(attempt: number, config: RetryConfig): number {
    let delay = config.retryDelayMs;
    
    if (config.exponentialBackoff) {
      delay *= Math.pow(2, attempt);
    }
    
    return Math.min(delay, config.maxRetryDelayMs || Infinity);
  }
}
```

### é”™è¯¯åˆ†ç±»å¤„ç†
```typescript
enum JobErrorType {
  TIMEOUT = 'TIMEOUT',
  NETWORK_ERROR = 'NETWORK_ERROR',
  VALIDATION_ERROR = 'VALIDATION_ERROR',
  SYSTEM_ERROR = 'SYSTEM_ERROR',
  USER_ERROR = 'USER_ERROR'
}

@Injectable()
export class ErrorClassifier {
  classifyError(error: Error): JobErrorType {
    if (error.name === 'TimeoutError') {
      return JobErrorType.TIMEOUT;
    }
    
    if (error.message.includes('ECONNREFUSED')) {
      return JobErrorType.NETWORK_ERROR;
    }
    
    // å…¶ä»–åˆ†ç±»é€»è¾‘
    return JobErrorType.SYSTEM_ERROR;
  }
  
  shouldRetry(errorType: JobErrorType): boolean {
    const retryableErrors = [
      JobErrorType.TIMEOUT,
      JobErrorType.NETWORK_ERROR,
      JobErrorType.SYSTEM_ERROR
    ];
    
    return retryableErrors.includes(errorType);
  }
}
```

## åˆ†å¸ƒå¼é”å®ç°

### Redisåˆ†å¸ƒå¼é”
```typescript
@Injectable()
export class DistributedLockService {
  constructor(private readonly redis: Redis) {}
  
  async acquireLock(
    key: string, 
    ttlMs: number = 30000,
    identifier?: string
  ): Promise<string | null> {
    const lockId = identifier || uuidv4();
    const lockKey = `lock:${key}`;
    
    const result = await this.redis.set(
      lockKey, 
      lockId, 
      'PX', 
      ttlMs, 
      'NX'
    );
    
    return result === 'OK' ? lockId : null;
  }
  
  async releaseLock(key: string, lockId: string): Promise<boolean> {
    const script = `
      if redis.call("GET", KEYS[1]) == ARGV[1] then
        return redis.call("DEL", KEYS[1])
      else
        return 0
      end
    `;
    
    const result = await this.redis.eval(
      script, 
      1, 
      `lock:${key}`, 
      lockId
    );
    
    return result === 1;
  }
  
  async extendLock(key: string, lockId: string, ttlMs: number): Promise<boolean> {
    const script = `
      if redis.call("GET", KEYS[1]) == ARGV[1] then
        return redis.call("PEXPIRE", KEYS[1], ARGV[2])
      else
        return 0
      end
    `;
    
    const result = await this.redis.eval(
      script,
      1,
      `lock:${key}`,
      lockId,
      ttlMs.toString()
    );
    
    return result === 1;
  }
}
```

### è°ƒåº¦é”ç®¡ç†
```typescript
@Injectable()
export class SchedulerLockManager {
  async withLock<T>(
    jobId: string,
    operation: () => Promise<T>,
    ttlMs: number = 30000
  ): Promise<T> {
    const lockKey = `scheduler:job:${jobId}`;
    const lockId = await this.lockService.acquireLock(lockKey, ttlMs);
    
    if (!lockId) {
      throw new Error(`Failed to acquire lock for job ${jobId}`);
    }
    
    try {
      return await operation();
    } finally {
      await this.lockService.releaseLock(lockKey, lockId);
    }
  }
}
```

## ç›‘æ§æŒ‡æ ‡

### ä¸šåŠ¡æŒ‡æ ‡
```typescript
interface SchedulerMetrics {
  // ä»»åŠ¡ç»Ÿè®¡
  totalJobs: number;
  activeJobs: number;
  pausedJobs: number;
  
  // æ‰§è¡Œç»Ÿè®¡
  totalExecutions: number;
  successfulExecutions: number;
  failedExecutions: number;
  cancelledExecutions: number;
  
  // æ€§èƒ½æŒ‡æ ‡
  averageExecutionTime: number;
  queueLength: number;
  activeWorkers: number;
  
  // é”™è¯¯ç‡
  errorRate: number;
  timeoutRate: number;
  retryRate: number;
}

@Injectable()
export class MetricsCollector {
  @Cron('*/30 * * * * *') // æ¯30ç§’æ”¶é›†ä¸€æ¬¡
  async collectMetrics(): Promise<void> {
    const metrics = await this.calculateMetrics();
    
    // å‘é€åˆ°ç›‘æ§ç³»ç»Ÿ
    this.prometheusService.setGauge('scheduler_total_jobs', metrics.totalJobs);
    this.prometheusService.setGauge('scheduler_queue_length', metrics.queueLength);
    this.prometheusService.setGauge('scheduler_error_rate', metrics.errorRate);
    
    // å‘é€åˆ°æ•°æ®åº“
    await this.metricsRepository.save(metrics);
  }
}
```

### æ€§èƒ½ç›‘æ§
```typescript
// PrometheusæŒ‡æ ‡å®šä¹‰
const schedulerMetrics = {
  jobExecutions: new Counter({
    name: 'scheduler_job_executions_total',
    help: 'Total number of job executions',
    labelNames: ['job_type', 'status', 'tenant_id']
  }),
  
  executionDuration: new Histogram({
    name: 'scheduler_execution_duration_seconds',
    help: 'Job execution duration in seconds',
    labelNames: ['job_type', 'tenant_id'],
    buckets: [0.1, 0.5, 1, 5, 10, 30, 60, 300]
  }),
  
  queueSize: new Gauge({
    name: 'scheduler_queue_size',
    help: 'Current size of job queue',
    labelNames: ['queue_name']
  })
};
```

## APIè®¾è®¡è§„èŒƒ

### ä»»åŠ¡åˆ›å»ºè¯·æ±‚
```typescript
interface CreateJobRequest {
  name: string;
  description?: string;
  cronExpression: string;
  timezone?: string;
  jobType: 'http' | 'function' | 'command';
  config: HttpJobConfig | FunctionJobConfig | CommandJobConfig;
  retryConfig?: RetryConfig;
  timeout?: number;
  priority?: number;
  startDate?: string;
  endDate?: string;
  maxExecutions?: number;
  tags?: string[];
}

interface JobResponse {
  id: string;
  name: string;
  status: 'active' | 'paused' | 'inactive';
  cronExpression: string;
  nextExecutionAt: string;
  lastExecutionAt?: string;
  executionCount: number;
  createdAt: string;
  updatedAt: string;
}
```

### é”™è¯¯å“åº”æ ¼å¼
```typescript
enum SchedulerErrorCode {
  INVALID_CRON_EXPRESSION = 'INVALID_CRON_EXPRESSION',
  JOB_NOT_FOUND = 'JOB_NOT_FOUND',
  JOB_ALREADY_RUNNING = 'JOB_ALREADY_RUNNING',
  INVALID_JOB_CONFIG = 'INVALID_JOB_CONFIG',
  LOCK_ACQUISITION_FAILED = 'LOCK_ACQUISITION_FAILED',
  QUOTA_EXCEEDED = 'QUOTA_EXCEEDED'
}

interface SchedulerErrorResponse {
  error: {
    code: SchedulerErrorCode;
    message: string;
    details?: any;
  };
  timestamp: string;
  path: string;
}
```

## éƒ¨ç½²é…ç½®

### ç¯å¢ƒå˜é‡
```env
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://user:password@localhost:5432/scheduler
REDIS_URL=redis://localhost:6379

# è°ƒåº¦é…ç½®
SCHEDULER_WORKER_COUNT=5
SCHEDULER_MAX_CONCURRENT_JOBS=100
SCHEDULER_JOB_TIMEOUT_MS=300000
SCHEDULER_LOCK_TTL_MS=30000

# é˜Ÿåˆ—é…ç½®
BULL_REDIS_HOST=localhost
BULL_REDIS_PORT=6379
BULL_REDIS_DB=1

# ç›‘æ§é…ç½®
METRICS_ENABLED=true
PROMETHEUS_PORT=9464
LOG_LEVEL=info
```

### Dockeré…ç½®
```dockerfile
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY dist/ ./dist/

EXPOSE 3009 9464

CMD ["node", "dist/main.js"]
```

## æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•
```typescript
describe('CronParser', () => {
  it('should parse valid cron expression', () => {
    const parser = new CronParser();
    const result = parser.parseExpression('0 */5 * * * *');
    expect(result).toBeDefined();
  });
  
  it('should reject invalid cron expression', () => {
    const parser = new CronParser();
    expect(() => parser.parseExpression('invalid')).toThrow();
  });
});

describe('DistributedLockService', () => {
  it('should acquire and release lock successfully', async () => {
    const lockId = await lockService.acquireLock('test-key', 5000);
    expect(lockId).toBeTruthy();
    
    const released = await lockService.releaseLock('test-key', lockId);
    expect(released).toBe(true);
  });
});
```

### é›†æˆæµ‹è¯•
```typescript
describe('Job Execution', () => {
  it('should execute HTTP job successfully', async () => {
    const job = await createTestJob({
      type: 'http',
      config: {
        url: 'https://httpbin.org/get',
        method: 'GET'
      }
    });
    
    const execution = await triggerJob(job.id);
    await waitForCompletion(execution.id);
    
    const result = await getExecution(execution.id);
    expect(result.status).toBe('completed');
    expect(result.result.success).toBe(true);
  });
});
```

## æ€§èƒ½ä¼˜åŒ–

### æ•°æ®åº“ä¼˜åŒ–
```sql
-- å…³é”®ç´¢å¼•
CREATE INDEX idx_scheduled_jobs_next_execution ON scheduled_jobs(next_execution_at) WHERE status = 'active';
CREATE INDEX idx_job_executions_job_id_created ON job_executions(job_id, created_at DESC);
CREATE INDEX idx_job_executions_status_tenant ON job_executions(status, tenant_id);

-- åˆ†åŒºè¡¨ï¼ˆæŒ‰æœˆåˆ†åŒºï¼‰
CREATE TABLE job_executions_y2024m01 PARTITION OF job_executions
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

### ç¼“å­˜ç­–ç•¥
```typescript
// ä»»åŠ¡é…ç½®ç¼“å­˜
Cache Key: scheduler:job_config:{jobId}
TTL: 1å°æ—¶

// æ‰§è¡Œç»Ÿè®¡ç¼“å­˜
Cache Key: scheduler:stats:{tenantId}:{date}
TTL: 24å°æ—¶

// ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´ç¼“å­˜
Cache Key: scheduler:next_execution:{jobId}
TTL: æ ¹æ®ä»»åŠ¡é¢‘ç‡åŠ¨æ€è®¾ç½®
```

## é¡¹ç›®è§„åˆ’

### å¼€å‘é‡Œç¨‹ç¢‘ (Week 3)

**é˜¶æ®µä¸€ï¼šæ ¸å¿ƒè°ƒåº¦åŠŸèƒ½** (Week 3.1-3.3)
- ğŸ¯ é‡Œç¨‹ç¢‘1ï¼šå®Œæˆä»»åŠ¡å®šä¹‰ç®¡ç†å’Œæ‰§è¡Œæ§åˆ¶ç³»ç»Ÿ
- ğŸ¯ é‡Œç¨‹ç¢‘2ï¼šå®ç°Cronè¡¨è¾¾å¼è§£æå’Œåˆ†å¸ƒå¼é”ç®¡ç†
- ğŸ¯ é‡Œç¨‹ç¢‘3ï¼šé›†æˆBullMQé˜Ÿåˆ—å’Œé‡è¯•æœºåˆ¶

**é˜¶æ®µäºŒï¼šæœåŠ¡é›†æˆ** (Week 3.4-3.5)
- ğŸ¯ é‡Œç¨‹ç¢‘4ï¼šé›†æˆè®¤è¯æœåŠ¡å’Œæƒé™ç®¡ç†æœåŠ¡
- ğŸ¯ é‡Œç¨‹ç¢‘5ï¼šé›†æˆå®¡è®¡æœåŠ¡å’Œç›‘æ§æœåŠ¡

**é˜¶æ®µä¸‰ï¼šç”Ÿäº§ä¼˜åŒ–** (Week 3.6-3.7)
- ğŸ¯ é‡Œç¨‹ç¢‘6ï¼šæ€§èƒ½ä¼˜åŒ–å’Œå‹åŠ›æµ‹è¯•
- ğŸ¯ é‡Œç¨‹ç¢‘7ï¼šéƒ¨ç½²é…ç½®å’Œç›‘æ§å‘Šè­¦

### èµ„æºåˆ†é…

**å†…å­˜åˆ†é… (åŸºäº8GBæ€»å†…å­˜æ¶æ„)**
- ä»»åŠ¡è°ƒåº¦æœåŠ¡ï¼š640MB (åŸºç¡€è¿è¡Œ) + 384MB (é˜Ÿåˆ—ç¼“å­˜) = 1024MB
- å¤„ç†èƒ½åŠ›ï¼šæ”¯æŒ1000ä¸ªå¹¶å‘ä»»åŠ¡ï¼Œæ¯å¤©100ä¸‡ä¸ªä»»åŠ¡
- é˜Ÿåˆ—å®¹é‡ï¼šBullMQé˜Ÿåˆ—æœ€å¤§20000ä¸ªä»»åŠ¡ï¼Œæ”¯æŒå»¶æ—¶æ‰§è¡Œ

**å¼€å‘ä¼˜å…ˆçº§**
1. **P0 (å¿…é¡»)**: ä»»åŠ¡å®šä¹‰ã€Cronè°ƒåº¦ã€ä»»åŠ¡æ‰§è¡Œ
2. **P1 (é‡è¦)**: åˆ†å¸ƒå¼é”ã€BullMQé˜Ÿåˆ—ã€é‡è¯•æœºåˆ¶
3. **P2 (ä¸€èˆ¬)**: æ‰§è¡Œå†å²ã€æ€§èƒ½ç›‘æ§ã€é«˜çº§è°ƒåº¦ç­–ç•¥

### é£é™©è¯„ä¼°

**æŠ€æœ¯é£é™©**
- âš ï¸ **é«˜é£é™©**: åˆ†å¸ƒå¼é”ç«äº‰å’Œè°ƒåº¦å™¨è„‘è£‚é—®é¢˜
- âš ï¸ **ä¸­é£é™©**: BullMQé˜Ÿåˆ—æ€§èƒ½ç“¶é¢ˆå’Œä»»åŠ¡ç§¯å‹
- âš ï¸ **ä½é£é™©**: Cronè¡¨è¾¾å¼è§£æé”™è¯¯å’Œæ—¶åŒºå¤„ç†

**æœåŠ¡ä¾èµ–é£é™©**
- ğŸ”´ **å¼ºä¾èµ–**: è®¤è¯æœåŠ¡(ä»»åŠ¡æˆæƒ)ã€æƒé™æœåŠ¡(æƒé™æ£€æŸ¥)
- ğŸŸ¡ **ä¸­ä¾èµ–**: å®¡è®¡æœåŠ¡(ä»»åŠ¡å®¡è®¡)ã€ç›‘æ§æœåŠ¡(æ€§èƒ½æŒ‡æ ‡)
- ğŸŸ¢ **å¼±ä¾èµ–**: é€šçŸ¥æœåŠ¡(ä»»åŠ¡çŠ¶æ€é€šçŸ¥)ã€ç”¨æˆ·æœåŠ¡(ç”¨æˆ·ä¿¡æ¯)

**ç¼“è§£ç­–ç•¥**
- å®ç°åˆ†å¸ƒå¼é”çš„è¶…æ—¶å’Œè‡ªåŠ¨é‡Šæ”¾æœºåˆ¶
- è®¾ç½®BullMQé˜Ÿåˆ—ç›‘æ§å’Œè‡ªåŠ¨æ‰©å®¹
- å»ºç«‹ä»»åŠ¡é™çº§å’Œå®¹é”™ä¿æŠ¤

## æœåŠ¡é—´äº¤äº’è®¾è®¡

### å†…éƒ¨APIæ¥å£

```typescript
// å†…éƒ¨æœåŠ¡è°ƒç”¨æ¥å£
@Controller('internal')
export class InternalSchedulerController {
  @Post('jobs/create')
  @UseGuards(ServiceTokenGuard)
  async createInternalJob(@Body() dto: InternalCreateJobDto) {
    // å†…éƒ¨æœåŠ¡åˆ›å»ºä»»åŠ¡
    return this.schedulerService.createInternalJob(dto)
  }

  @Post('jobs/{jobId}/trigger')
  @UseGuards(ServiceTokenGuard)
  async triggerJob(@Param('jobId') jobId: string, @Body() dto: TriggerJobDto) {
    // æ‰‹åŠ¨è§¦å‘ä»»åŠ¡
    return this.schedulerService.triggerJob(jobId, dto)
  }

  @Get('jobs/{jobId}/status')
  @UseGuards(ServiceTokenGuard)
  async getJobStatus(@Param('jobId') jobId: string) {
    // è·å–ä»»åŠ¡çŠ¶æ€
    return this.schedulerService.getJobStatus(jobId)
  }

  @Post('jobs/batch-create')
  @UseGuards(ServiceTokenGuard)
  async createBatchJobs(@Body() dto: BatchCreateJobsDto) {
    // æ‰¹é‡åˆ›å»ºä»»åŠ¡
    return this.schedulerService.createBatchJobs(dto)
  }

  @Get('health')
  async getServiceHealth() {
    // æœåŠ¡å¥åº·æ£€æŸ¥
    return this.healthService.check()
  }

  @Post('jobs/{jobId}/pause')
  @UseGuards(ServiceTokenGuard)
  async pauseJob(@Param('jobId') jobId: string) {
    // æš‚åœä»»åŠ¡
    return this.schedulerService.pauseJob(jobId)
  }

  @Post('jobs/{jobId}/resume')
  @UseGuards(ServiceTokenGuard)
  async resumeJob(@Param('jobId') jobId: string) {
    // æ¢å¤ä»»åŠ¡
    return this.schedulerService.resumeJob(jobId)
  }
}
```

### æœåŠ¡é—´è®¤è¯æœºåˆ¶

```typescript
// X-Service-TokenéªŒè¯
@Injectable()
export class ServiceTokenGuard implements CanActivate {
  canActivate(context: ExecutionContext): boolean {
    const request = context.switchToHttp().getRequest()
    const serviceToken = request.headers['x-service-token']
    
    // éªŒè¯å†…éƒ¨æœåŠ¡ä»¤ç‰Œ
    return this.validateServiceToken(serviceToken)
  }

  private validateServiceToken(token: string): boolean {
    // éªŒè¯é€»è¾‘ï¼šæ£€æŸ¥ä»¤ç‰Œæ˜¯å¦æœ‰æ•ˆ
    return token === process.env.INTERNAL_SERVICE_TOKEN
  }
}
```

### ç»Ÿä¸€é”™è¯¯å¤„ç†

```typescript
// ç»Ÿä¸€é”™è¯¯å“åº”æ ¼å¼
export class SchedulerErrorHandler {
  handleError(error: any): ServiceErrorResponse {
    return {
      success: false,
      errorCode: error.code || 'SCHEDULER_ERROR',
      message: error.message,
      timestamp: new Date().toISOString(),
      serviceName: 'scheduler-service'
    }
  }
}

// ä»»åŠ¡æ‰§è¡Œé‡è¯•æœºåˆ¶
@Injectable()
export class JobRetryService {
  async executeWithRetry(
    jobId: string,
    jobFunction: () => Promise<any>,
    retryConfig: RetryConfig
  ): Promise<JobResult> {
    let lastError: Error
    
    for (let attempt = 0; attempt <= retryConfig.maxRetries; attempt++) {
      try {
        const result = await jobFunction()
        return {
          success: true,
          result: result,
          attempt: attempt + 1
        }
      } catch (error) {
        lastError = error
        
        if (attempt === retryConfig.maxRetries) {
          break
        }
        
        // è®¡ç®—é‡è¯•å»¶è¿Ÿ
        const delay = this.calculateDelay(attempt, retryConfig)
        await this.delay(delay)
        
        // è®°å½•é‡è¯•æ—¥å¿—
        await this.auditService.logJobRetry(jobId, attempt + 1, error.message)
      }
    }
    
    return {
      success: false,
      error: lastError.message,
      attempt: retryConfig.maxRetries + 1
    }
  }
}
```

## éƒ¨ç½²é…ç½®

### Docker Compose é…ç½®
```yaml
# docker-compose.yml
version: '3.8'
services:
  scheduler-service:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: scheduler-service
    ports:
      - "3009:3009"
      - "9464:9464"  # Prometheus metrics
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://user:pass@postgres:5432/platform
      - REDIS_URL=redis://redis:6379/3
      - INTERNAL_SERVICE_TOKEN=${INTERNAL_SERVICE_TOKEN}
      - AUTH_SERVICE_URL=http://auth-service:3001
      - RBAC_SERVICE_URL=http://rbac-service:3002
      - AUDIT_SERVICE_URL=http://audit-service:3008
      - NOTIFICATION_SERVICE_URL=http://notification-service:3005
      - SCHEDULER_WORKER_COUNT=5
      - SCHEDULER_MAX_CONCURRENT_JOBS=1000
      - SCHEDULER_JOB_TIMEOUT_MS=300000
      - SCHEDULER_LOCK_TTL_MS=30000
    volumes:
      - ./logs:/app/logs
    networks:
      - platform-network
    depends_on:
      - postgres
      - redis
    deploy:
      resources:
        limits:
          memory: 1024M
          cpus: '0.75'
        reservations:
          memory: 640M
          cpus: '0.5'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3009/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ä»»åŠ¡æ‰§è¡Œå™¨ (ç‹¬ç«‹è¿›ç¨‹)
  scheduler-worker:
    build: 
      context: .
      dockerfile: Dockerfile.worker
    container_name: scheduler-worker
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://user:pass@postgres:5432/platform
      - REDIS_URL=redis://redis:6379/3
      - WORKER_CONCURRENCY=10
      - JOB_TIMEOUT=300000
    networks:
      - platform-network
    depends_on:
      - postgres
      - redis
      - scheduler-service
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    scale: 2  # è¿è¡Œ2ä¸ªworkerå®ä¾‹

networks:
  platform-network:
    external: true
```

### å¿«é€Ÿå¼€å§‹

```bash
# 1. å¯åŠ¨åŸºç¡€è®¾æ–½
docker-compose up -d postgres redis

# 2. å®‰è£…ä¾èµ–
npm install

# 3. æ•°æ®åº“è¿ç§»
npx prisma migrate dev

# 4. åˆå§‹åŒ–è°ƒåº¦å™¨
npm run seed:scheduler

# 5. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
nx serve scheduler-service

# 6. å¯åŠ¨å·¥ä½œè¿›ç¨‹
npm run start:worker

# 7. æµ‹è¯•ä»»åŠ¡åˆ›å»ºAPI
curl -X POST http://localhost:3009/api/v1/scheduler/jobs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "name": "Test Job",
    "cronExpression": "0 */5 * * * *",
    "jobType": "http",
    "config": {
      "url": "https://httpbin.org/get",
      "method": "GET"
    }
  }'
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env
NODE_ENV=development
PORT=3009

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://user:pass@localhost:5432/platform
REDIS_URL=redis://localhost:6379/3

# æœåŠ¡é—´é€šä¿¡
INTERNAL_SERVICE_TOKEN=your-internal-service-token
AUTH_SERVICE_URL=http://auth-service:3001
RBAC_SERVICE_URL=http://rbac-service:3002
AUDIT_SERVICE_URL=http://audit-service:3008
NOTIFICATION_SERVICE_URL=http://notification-service:3005

# è°ƒåº¦å™¨é…ç½®
SCHEDULER_WORKER_COUNT=5
SCHEDULER_MAX_CONCURRENT_JOBS=1000
SCHEDULER_JOB_TIMEOUT_MS=300000
SCHEDULER_LOCK_TTL_MS=30000

# BullMQé…ç½®
BULL_REDIS_HOST=localhost
BULL_REDIS_PORT=6379
BULL_REDIS_DB=3
BULL_MAX_STALLED_COUNT=3
BULL_STALLED_INTERVAL=30000

# ç›‘æ§é…ç½®
METRICS_ENABLED=true
PROMETHEUS_PORT=9464
LOG_LEVEL=info

# ä»»åŠ¡é™åˆ¶
MAX_JOBS_PER_TENANT=1000
MAX_EXECUTIONS_PER_HOUR=10000
JOB_EXECUTION_TIMEOUT=600000
```

## ç”Ÿäº§éƒ¨ç½²æ£€æŸ¥æ¸…å•

### éƒ¨ç½²å‰æ£€æŸ¥
- [ ] ç¡®è®¤æœåŠ¡å™¨èµ„æºï¼š1024MBå†…å­˜ï¼Œ0.75CPUæ ¸å¿ƒ
- [ ] é…ç½®æ‰€æœ‰å¿…éœ€çš„ç¯å¢ƒå˜é‡
- [ ] è®¾ç½®RedisæŒä¹…åŒ–å’Œå¤‡ä»½
- [ ] é…ç½®BullMQé˜Ÿåˆ—å‚æ•°
- [ ] è®¾ç½®ä»»åŠ¡æ‰§è¡Œæ—¥å¿—è½®è½¬
- [ ] éªŒè¯ä¸å…¶ä»–æœåŠ¡çš„ç½‘ç»œè¿é€šæ€§
- [ ] æµ‹è¯•åˆ†å¸ƒå¼é”æ­£å¸¸å·¥ä½œ

### æœåŠ¡å¯åŠ¨é¡ºåº
1. PostgreSQL, Redis (åŸºç¡€è®¾æ–½)
2. auth-service, rbac-service (ä¾èµ–æœåŠ¡)
3. scheduler-service (ä¸»æœåŠ¡)
4. scheduler-worker (å·¥ä½œè¿›ç¨‹)

### ç›‘æ§æŒ‡æ ‡
- ä»»åŠ¡æ‰§è¡ŒæˆåŠŸç‡ > 99.9%
- ä»»åŠ¡è°ƒåº¦å»¶è¿Ÿ < 10ç§’
- é˜Ÿåˆ—ç§¯å‹ä»»åŠ¡ < 5000ä¸ª
- æœåŠ¡å†…å­˜ä½¿ç”¨ < 900MB
- APIå“åº”æ—¶é—´P95 < 100ms
- åˆ†å¸ƒå¼é”è·å–æˆåŠŸç‡ > 95%

### å®‰å…¨è€ƒè™‘

#### ä»»åŠ¡éš”ç¦»
- ç§Ÿæˆ·çº§åˆ«çš„ä»»åŠ¡éš”ç¦»
- èµ„æºä½¿ç”¨é™åˆ¶
- æ‰§è¡Œæ—¶é—´é™åˆ¶
- å¹¶å‘æ•°é™åˆ¶

#### æƒé™æ§åˆ¶
- ä»»åŠ¡åˆ›å»ºæƒé™éªŒè¯
- æ‰§è¡Œç»“æœè®¿é—®æ§åˆ¶
- æ•æ„Ÿé…ç½®åŠ å¯†å­˜å‚¨
- å®¡è®¡æ—¥å¿—è®°å½•

---

è¿™ä¸ªä»»åŠ¡è°ƒåº¦æœåŠ¡ä¸ºæ•´ä¸ªå¾®æœåŠ¡å¹³å°æä¾›å¼ºå¤§çš„å®šæ—¶ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ï¼Œæ”¯æŒ100ç§Ÿæˆ·+10ä¸‡ç”¨æˆ·çš„ä¼ä¸šçº§ä»»åŠ¡è°ƒåº¦ï¼Œæä¾›å¯é ã€é«˜æ€§èƒ½ã€å¯æ‰©å±•çš„å®šæ—¶ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ï¼Œæ»¡è¶³ä¼ä¸šçº§åº”ç”¨çš„å„ç§è°ƒåº¦éœ€æ±‚ã€‚é€šè¿‡æ ‡å‡†ç‰ˆæœ¬çš„ä¼˜åŒ–è®¾è®¡ï¼Œç¡®ä¿åœ¨Week 3å†…å®Œæˆå¼€å‘å’Œéƒ¨ç½²ã€‚