# æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡å¼€å‘æŒ‡å—

## ğŸ¯ æœåŠ¡æ¦‚è¿°

æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡æ˜¯å¾®æœåŠ¡å¹³å°çš„æ¶ˆæ¯ä¸­é—´ä»¶æ ¸å¿ƒï¼Œé¢å‘**100ç§Ÿæˆ·+10ä¸‡ç”¨æˆ·**çš„ä¼ä¸šçº§ç”Ÿäº§ç³»ç»Ÿï¼Œè´Ÿè´£å¼‚æ­¥æ¶ˆæ¯ä¼ é€’ã€æœåŠ¡è§£è€¦ã€äº‹ä»¶é©±åŠ¨æ¶æ„å’Œå¯é æ¶ˆæ¯ä¼ è¾“ï¼Œä¸ºæ•´ä¸ªå¹³å°æä¾›é«˜æ€§èƒ½ã€é«˜å¯ç”¨çš„æ¶ˆæ¯é€šä¿¡èƒ½åŠ›ã€‚

### æ ¸å¿ƒåŠŸèƒ½
- **é˜Ÿåˆ—ç®¡ç†**: åˆ›å»ºã€é…ç½®ã€ç›‘æ§æ¶ˆæ¯é˜Ÿåˆ—
- **æ¶ˆæ¯å‘å¸ƒ**: æ”¯æŒå•æ¡ã€æ‰¹é‡ã€å»¶è¿Ÿã€å®šæ—¶æ¶ˆæ¯å‘å¸ƒ
- **æ¶ˆæ¯è®¢é˜…**: çµæ´»çš„è®¢é˜…ç®¡ç†å’Œæ¶ˆè´¹è€…ç»„é…ç½®
- **ç›‘æ§ç»Ÿè®¡**: å®æ—¶æ¶ˆæ¯å¤„ç†æŒ‡æ ‡å’Œç³»ç»Ÿå¥åº·çŠ¶æ€

### æœåŠ¡å®šä½
- **ç«¯å£**: 3010
- **ä¾èµ–å…³ç³»**: ä¾èµ–ç”¨æˆ·ç®¡ç†(3003)ã€è®¤è¯æˆæƒ(3001)ã€APIç½‘å…³(3000)
- **ä¼˜å…ˆçº§**: â­â­â­â­ (Week 3-4 æ‰©å±•æœåŠ¡)
- **å¤æ‚åº¦**: é«˜ - Redis Streams + PostgreSQL

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

### æ ‡å‡†ç‰ˆæœ¬æŠ€æœ¯é€‰æ‹© âœ…
- **æ¶ˆæ¯å­˜å‚¨**: Redis Streams (é€‚åˆæ ‡å‡†ç‰ˆæœ¬ååé‡)
- **å…ƒæ•°æ®å­˜å‚¨**: PostgreSQL (å¤ç”¨ç°æœ‰æ•°æ®åº“)
- **æ¡†æ¶**: NestJS 10.x + TypeScript 5.x (ç»Ÿä¸€æŠ€æœ¯æ ˆ)
- **éƒ¨ç½²**: Docker Compose (é¿å…K8Så¤æ‚æ€§)
- **åºåˆ—åŒ–**: JSON (ç®€åŒ–å¤„ç†)

### ä¼ä¸šç‰ˆæœ¬æ‰©å±•è®¡åˆ’ â­ (V2.0ç‰ˆæœ¬)
- **é«˜çº§æ¶ˆæ¯é˜Ÿåˆ—**: ä¼ä¸šç‰ˆå¯é€‰Kafkaé›†æˆ
- **æ¶ˆæ¯å‹ç¼©**: Protobuf/Avroç­‰é«˜çº§åºåˆ—åŒ–
- **åˆ†å¸ƒå¼è·Ÿè¸ª**: Jaeger/Zipkiné›†æˆ

## ğŸ“‹ å®Œæ•´åŠŸèƒ½åˆ—è¡¨

### 1. é˜Ÿåˆ—ç®¡ç† (Queue Management)
- åˆ›å»ºé˜Ÿåˆ—/ä¸»é¢˜
- é˜Ÿåˆ—é…ç½®ç®¡ç†
- é˜Ÿåˆ—çŠ¶æ€ç›‘æ§
- é˜Ÿåˆ—æ¸…ç©ºå’Œåˆ é™¤

### 2. æ¶ˆæ¯å‘å¸ƒ (Message Publishing)
- å•æ¡æ¶ˆæ¯å‘å¸ƒ
- æ‰¹é‡æ¶ˆæ¯å‘å¸ƒ
- å»¶è¿Ÿæ¶ˆæ¯å‘å¸ƒ
- å®šæ—¶æ¶ˆæ¯å‘å¸ƒ
- æ¶ˆæ¯è·¯ç”±å’Œåˆ†åŒº

### 3. æ¶ˆæ¯è®¢é˜… (Message Subscription)
- è®¢é˜…åˆ›å»ºå’Œé…ç½®
- æ¶ˆè´¹è€…ç»„ç®¡ç†
- æ¶ˆæ¯æ¶ˆè´¹å’Œç¡®è®¤
- å¤±è´¥é‡è¯•æœºåˆ¶

### 4. ç›‘æ§ç»Ÿè®¡ (Monitoring & Metrics)
- æ¶ˆæ¯å¤„ç†æŒ‡æ ‡
- é˜Ÿåˆ—çŠ¶æ€ç›‘æ§
- æ¶ˆè´¹è€…æ€§èƒ½ç›‘æ§
- ç³»ç»Ÿå¥åº·æ£€æŸ¥

## ğŸ”— APIè®¾è®¡

### é˜Ÿåˆ—ç®¡ç†æ¥å£
```typescript
POST   /api/v1/mq/queues                     // åˆ›å»ºé˜Ÿåˆ—
GET    /api/v1/mq/queues                     // è·å–é˜Ÿåˆ—åˆ—è¡¨
GET    /api/v1/mq/queues/{name}              // è·å–é˜Ÿåˆ—è¯¦æƒ…
PUT    /api/v1/mq/queues/{name}              // æ›´æ–°é˜Ÿåˆ—é…ç½®
DELETE /api/v1/mq/queues/{name}              // åˆ é™¤é˜Ÿåˆ—
POST   /api/v1/mq/queues/{name}/purge        // æ¸…ç©ºé˜Ÿåˆ—
```

### æ¶ˆæ¯å‘å¸ƒæ¥å£
```typescript
POST   /api/v1/mq/publish                    // å‘å¸ƒå•æ¡æ¶ˆæ¯
POST   /api/v1/mq/publish/batch              // æ‰¹é‡å‘å¸ƒæ¶ˆæ¯
POST   /api/v1/mq/publish/delayed            // å»¶è¿Ÿæ¶ˆæ¯å‘å¸ƒ
POST   /api/v1/mq/publish/scheduled          // å®šæ—¶æ¶ˆæ¯å‘å¸ƒ
POST   /api/v1/mq/topics/{name}/publish      // å‘å¸ƒåˆ°æŒ‡å®šä¸»é¢˜
```

### æ¶ˆæ¯è®¢é˜…ç®¡ç†
```typescript
POST   /api/v1/mq/subscriptions              // åˆ›å»ºè®¢é˜…
GET    /api/v1/mq/subscriptions              // è·å–è®¢é˜…åˆ—è¡¨
GET    /api/v1/mq/subscriptions/{id}         // è·å–è®¢é˜…è¯¦æƒ…
PUT    /api/v1/mq/subscriptions/{id}         // æ›´æ–°è®¢é˜…
DELETE /api/v1/mq/subscriptions/{id}         // åˆ é™¤è®¢é˜…
POST   /api/v1/mq/subscriptions/{id}/pause   // æš‚åœè®¢é˜…
POST   /api/v1/mq/subscriptions/{id}/resume  // æ¢å¤è®¢é˜…
```

### ç›‘æ§ç»Ÿè®¡æ¥å£
```typescript
GET    /api/v1/mq/metrics                    // è·å–ç³»ç»ŸæŒ‡æ ‡
GET    /api/v1/mq/metrics/topics             // è·å–ä¸»é¢˜æŒ‡æ ‡
GET    /api/v1/mq/metrics/consumers          // è·å–æ¶ˆè´¹è€…æŒ‡æ ‡
GET    /api/v1/mq/health                     // å¥åº·æ£€æŸ¥
GET    /api/v1/mq/status                     // æœåŠ¡çŠ¶æ€
```

## ğŸ—„ï¸ æ•°æ®åº“è®¾è®¡

### ä¸»é¢˜è¡¨ (message_topics)
```sql
CREATE TABLE message_topics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(200) NOT NULL UNIQUE,
  display_name VARCHAR(200),
  description TEXT,
  
  -- ä¸»é¢˜é…ç½®
  topic_type VARCHAR(50) NOT NULL, -- 'kafka', 'redis_stream'
  partition_count INTEGER DEFAULT 1,
  replication_factor INTEGER DEFAULT 1,
  retention_ms BIGINT DEFAULT 604800000, -- 7å¤©
  
  -- æ¶ˆæ¯é…ç½®
  message_format VARCHAR(50) DEFAULT 'json', -- 'json', 'avro', 'protobuf'
  schema_definition JSONB,
  compression_type VARCHAR(20) DEFAULT 'none',
  
  -- è®¿é—®æ§åˆ¶
  tenant_id UUID NOT NULL,
  is_public BOOLEAN DEFAULT FALSE,
  allowed_producers JSONB DEFAULT '[]',
  allowed_consumers JSONB DEFAULT '[]',
  
  -- çŠ¶æ€ç®¡ç†
  status VARCHAR(20) DEFAULT 'active', -- 'active', 'paused', 'archived'
  
  -- æ—¶é—´æˆ³
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);
```

### è®¢é˜…è¡¨ (message_subscriptions)
```sql
CREATE TABLE message_subscriptions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  topic_id UUID REFERENCES message_topics(id) ON DELETE CASCADE,
  
  -- è®¢é˜…ä¿¡æ¯
  consumer_group VARCHAR(200) NOT NULL,
  consumer_name VARCHAR(200) NOT NULL,
  subscription_type VARCHAR(50) NOT NULL, -- 'kafka_consumer', 'redis_consumer', 'webhook'
  
  -- æ¶ˆè´¹é…ç½®
  offset_reset_policy VARCHAR(20) DEFAULT 'latest', -- 'earliest', 'latest'
  max_poll_records INTEGER DEFAULT 500,
  session_timeout_ms INTEGER DEFAULT 30000,
  heartbeat_interval_ms INTEGER DEFAULT 3000,
  
  -- æ¶ˆæ¯å¤„ç†
  handler_config JSONB NOT NULL, -- å¤„ç†å™¨é…ç½®
  dead_letter_queue VARCHAR(200),
  max_retry_attempts INTEGER DEFAULT 3,
  retry_delay_ms INTEGER DEFAULT 1000,
  
  -- è¿‡æ»¤å™¨
  message_filter JSONB, -- æ¶ˆæ¯è¿‡æ»¤æ¡ä»¶
  
  -- çŠ¶æ€ç®¡ç†
  status VARCHAR(20) DEFAULT 'active', -- 'active', 'paused', 'stopped'
  tenant_id UUID NOT NULL,
  
  -- æ—¶é—´æˆ³
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  last_consumed_at TIMESTAMP,
  
  UNIQUE(topic_id, consumer_group, consumer_name)
);
```

### æ¶ˆæ¯è®°å½•è¡¨ (message_records)
```sql
CREATE TABLE message_records (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  topic_id UUID REFERENCES message_topics(id),
  
  -- æ¶ˆæ¯æ ‡è¯†
  message_key VARCHAR(500),
  message_id VARCHAR(200) UNIQUE NOT NULL,
  correlation_id VARCHAR(200),
  
  -- æ¶ˆæ¯å†…å®¹
  headers JSONB DEFAULT '{}',
  payload JSONB,
  payload_size INTEGER,
  content_type VARCHAR(100) DEFAULT 'application/json',
  
  -- è·¯ç”±ä¿¡æ¯
  partition_id INTEGER,
  offset_value BIGINT,
  
  -- æ¶ˆæ¯çŠ¶æ€
  status VARCHAR(20) DEFAULT 'published', -- 'published', 'consumed', 'failed', 'dead_letter'
  retry_count INTEGER DEFAULT 0,
  
  -- æ—¶é—´ä¿¡æ¯
  published_at TIMESTAMP DEFAULT NOW(),
  scheduled_at TIMESTAMP,
  consumed_at TIMESTAMP,
  expires_at TIMESTAMP,
  
  -- å…ƒæ•°æ®
  producer_id VARCHAR(200),
  tenant_id UUID NOT NULL,
  trace_id VARCHAR(100)
);
```

### æ¶ˆè´¹è®°å½•è¡¨ (consumption_records)
```sql
CREATE TABLE consumption_records (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  subscription_id UUID REFERENCES message_subscriptions(id),
  message_id VARCHAR(200) NOT NULL,
  
  -- æ¶ˆè´¹ä¿¡æ¯
  consumer_instance VARCHAR(200) NOT NULL,
  partition_id INTEGER,
  offset_value BIGINT,
  
  -- å¤„ç†ç»“æœ
  status VARCHAR(20) NOT NULL, -- 'success', 'failed', 'retrying'
  processing_time_ms INTEGER,
  error_message TEXT,
  retry_count INTEGER DEFAULT 0,
  
  -- æ—¶é—´æˆ³
  consumed_at TIMESTAMP DEFAULT NOW(),
  processed_at TIMESTAMP,
  next_retry_at TIMESTAMP,
  
  -- å…ƒæ•°æ®
  tenant_id UUID NOT NULL
);
```

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„å®ç°

### æ ‡å‡†ç‰ˆæœ¬æ¶ˆæ¯æ¶æ„
**ç®€åŒ–æ¶æ„** - ä¸“æ³¨Redis Streamsï¼Œé¿å…è¿‡åº¦å¤æ‚æ€§ï¼š

```mermaid
graph TB
    Producer[æ¶ˆæ¯ç”Ÿäº§è€…] --> Gateway[APIç½‘å…³:3000]
    Gateway --> MQService[æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡:3010]
    
    MQService --> RedisStreams[Redis Streams]
    MQService --> PostgreSQL[PostgreSQLå…ƒæ•°æ®]
    
    RedisStreams --> ConsumerGroup[æ¶ˆè´¹è€…ç»„]
    ConsumerGroup --> MessageProcessor[æ¶ˆæ¯å¤„ç†å™¨]
    
    MessageProcessor --> UserService[ç”¨æˆ·æœåŠ¡:3003]
    MessageProcessor --> NotificationService[é€šçŸ¥æœåŠ¡:3005]
    MessageProcessor --> AuditService[å®¡è®¡æœåŠ¡:3008]
    
    MessageProcessor --> DeadLetter[æ­»ä¿¡é˜Ÿåˆ—]
    MessageProcessor --> Monitoring[ç›‘æ§æœåŠ¡:3007]
```

### Redis Streamså®ç°
```typescript
@Injectable()
export class MessagePublisher {
  constructor(
    private readonly redis: Redis,
    private readonly auditService: AuditService
  ) {}
  
  async publishMessage(request: PublishMessageRequest): Promise<PublishMessageResponse> {
    const stream = `mq:${request.queue}`;
    const messageData = {
      id: generateId(),
      payload: JSON.stringify(request.payload),
      headers: JSON.stringify(request.headers || {}),
      tenant_id: request.tenantId,
      created_at: Date.now().toString()
    };
    
    try {
      const messageId = await this.redis.xadd(
        stream,
        '*',
        ...Object.entries(messageData).flat()
      );
      
      await this.auditService.logOperation({
        operation: 'message_published',
        resource: `queue:${request.queue}`,
        tenantId: request.tenantId,
        details: { messageId, size: JSON.stringify(request.payload).length }
      });
      
      return {
        messageId,
        queue: request.queue,
        publishedAt: new Date()
      };
    } catch (error) {
      throw new MessagePublishException(
        `Failed to publish message to queue ${request.queue}`,
        error
      );
    }
  }
}
```

## ğŸ”„ æœåŠ¡é—´äº¤äº’è®¾è®¡

### å†…éƒ¨APIæ¥å£ (æœåŠ¡é—´é€šä¿¡)
```typescript
// å†…éƒ¨æœåŠ¡è°ƒç”¨ - ä½¿ç”¨X-Service-Tokenè®¤è¯
interface InternalMessageAPI {
  // ç”¨æˆ·æœåŠ¡è°ƒç”¨
  'POST /internal/mq/user-events',           // ç”¨æˆ·äº‹ä»¶å‘å¸ƒ
  'POST /internal/mq/user-notifications',   // ç”¨æˆ·é€šçŸ¥æ¶ˆæ¯
  
  // å®¡è®¡æœåŠ¡è°ƒç”¨
  'POST /internal/mq/audit-logs',           // å®¡è®¡æ—¥å¿—æ¶ˆæ¯
  'GET /internal/mq/audit-queue-status',    // å®¡è®¡é˜Ÿåˆ—çŠ¶æ€
  
  // é€šçŸ¥æœåŠ¡è°ƒç”¨
  'POST /internal/mq/notifications',        // é€šçŸ¥æ¶ˆæ¯å‘å¸ƒ
  'GET /internal/mq/notification-queue',    // é€šçŸ¥é˜Ÿåˆ—çŠ¶æ€
  
  // ç›‘æ§æœåŠ¡è°ƒç”¨
  'GET /internal/mq/metrics',              // æ¶ˆæ¯é˜Ÿåˆ—æŒ‡æ ‡
  'GET /internal/mq/health-detailed'       // è¯¦ç»†å¥åº·çŠ¶æ€
}
```

### ç»Ÿä¸€é”™è¯¯å¤„ç†
```typescript
// æ ‡å‡†ç‰ˆæœ¬é”™è¯¯å“åº”æ ¼å¼
interface MessageQueueError {
  code: 'MQ_QUEUE_NOT_FOUND' | 'MQ_PUBLISH_FAILED' | 'MQ_CONSUMER_ERROR';
  message: string;
  details?: any;
  retryAfter?: number; // é‡è¯•å»¶è¿Ÿ(ç§’)
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### æ‰¹é‡å¤„ç†ä¼˜åŒ–
```typescript
@Injectable()
export class BatchProcessor {
  private batches: Map<string, MessageBatch> = new Map();
  
  async addToBatch(topic: string, message: Message): Promise<void> {
    let batch = this.batches.get(topic);
    
    if (!batch) {
      batch = new MessageBatch(topic, this.config.batchSize);
      this.batches.set(topic, batch);
    }
    
    batch.addMessage(message);
    
    if (batch.isFull() || batch.isExpired()) {
      await this.processBatch(batch);
      this.batches.delete(topic);
    }
  }
}
```

### è¿æ¥æ± ç®¡ç†
- Redisè¿æ¥æ± ï¼š5-20ä¸ªè¿æ¥
- æ¶ˆæ¯æ‰¹é‡å¤§å°ï¼š50æ¡/æ‰¹æ¬¡
- æœ€å¤§å¹¶å‘æ¶ˆè´¹è€…ï¼š5ä¸ª
- å¤„ç†è¶…æ—¶ï¼š15ç§’

## ğŸ›¡ï¸ å®‰å…¨æªæ–½

### æ¶ˆæ¯åŠ å¯†
```typescript
@Injectable()
export class MessageEncryption {
  async encryptMessage(payload: any, tenantKey: string): Promise<string> {
    const cipher = crypto.createCipher('aes-256-gcm', tenantKey);
    const encrypted = cipher.update(JSON.stringify(payload), 'utf8', 'hex') + 
                     cipher.final('hex');
    const authTag = cipher.getAuthTag();
    
    return Buffer.from(JSON.stringify({
      data: encrypted,
      authTag: authTag.toString('hex')
    })).toString('base64');
  }
}
```

### è®¿é—®æ§åˆ¶
- ç§Ÿæˆ·çº§åˆ«æ¶ˆæ¯éš”ç¦»
- ç”Ÿäº§è€…/æ¶ˆè´¹è€…æƒé™éªŒè¯
- å†…éƒ¨æœåŠ¡é—´APIè®¤è¯
- æ¶ˆæ¯ä¼ è¾“åŠ å¯†

## ğŸ“ˆ ç›‘æ§å’Œå‘Šè­¦

### ç³»ç»ŸæŒ‡æ ‡
```typescript
interface MessageQueueMetrics {
  redisStreams: {
    totalStreams: number;
    totalConsumerGroups: number;
    totalMessages: number;
    pendingMessages: number;
  };
  
  consumers: {
    activeConsumers: number;
    totalLag: number;
    processingRate: number;
    errorRate: number;
  };
  
  performance: {
    averageLatency: number;
    p95Latency: number;
    p99Latency: number;
    throughput: number;
  };
}
```

### å¥åº·æ£€æŸ¥å®ç°
```typescript
// æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡å¥åº·æ£€æŸ¥æ§åˆ¶å™¨
@Controller('health')
export class MessageQueueHealthController {
  constructor(
    private readonly redis: Redis,
    private readonly prisma: PrismaService,
    private readonly messageQueueService: MessageQueueService
  ) {}

  @Get()
  async checkHealth(): Promise<HealthCheckResponse> {
    const startTime = Date.now();
    
    const checks = await Promise.allSettled([
      this.checkRedisStreams(),
      this.checkDatabase(),
      this.checkQueues(),
      this.checkConsumers(),
      this.checkMemory(),
      this.checkDependencies()
    ]);
    
    const redisStatus = checks[0].status === 'fulfilled' ? 'healthy' : 'unhealthy';
    const databaseStatus = checks[1].status === 'fulfilled' ? 'healthy' : 'unhealthy';
    const queuesStatus = checks[2].status === 'fulfilled' ? 'healthy' : 'unhealthy';
    const consumersStatus = checks[3].status === 'fulfilled' ? 'healthy' : 'unhealthy';
    const memoryStatus = checks[4].status === 'fulfilled' ? 'healthy' : 'unhealthy';
    const dependenciesStatus = checks[5].status === 'fulfilled' ? 'healthy' : 'unhealthy';
    
    const overallStatus = [redisStatus, databaseStatus, queuesStatus, consumersStatus, memoryStatus, dependenciesStatus]
      .every(status => status === 'healthy') ? 'healthy' : 'unhealthy';
    
    const responseTime = Date.now() - startTime;
    
    return {
      status: overallStatus,
      timestamp: new Date().toISOString(),
      service: 'message-queue-service',
      version: '1.0.0',
      uptime: process.uptime(),
      responseTime,
      checks: {
        redisStreams: redisStatus,
        database: databaseStatus,
        queues: queuesStatus,
        consumers: consumersStatus,
        memory: memoryStatus,
        dependencies: dependenciesStatus
      },
      metrics: await this.getHealthMetrics()
    };
  }

  @Get('ping')
  async ping(): Promise<{ status: string; timestamp: string; latency: number }> {
    const startTime = Date.now();
    
    try {
      await this.redis.ping();
      const latency = Date.now() - startTime;
      
      return {
        status: 'pong',
        timestamp: new Date().toISOString(),
        latency
      };
    } catch (error) {
      throw new ServiceUnavailableException('Redis connection failed');
    }
  }

  @Get('status')
  async getStatus(): Promise<MessageQueueStatusResponse> {
    const redisInfo = await this.redis.info();
    const memory = process.memoryUsage();
    const queuesInfo = await this.getQueuesInfo();
    
    return {
      service: 'message-queue-service',
      status: 'running',
      timestamp: new Date().toISOString(),
      redis: {
        version: redisInfo.redis_version,
        uptime: parseInt(redisInfo.uptime_in_seconds),
        connectedClients: parseInt(redisInfo.connected_clients),
        usedMemory: redisInfo.used_memory_human,
        totalCommandsProcessed: parseInt(redisInfo.total_commands_processed)
      },
      queues: queuesInfo,
      application: {
        nodeVersion: process.version,
        pid: process.pid,
        uptime: process.uptime(),
        memory: {
          rss: Math.round(memory.rss / 1024 / 1024),
          heapUsed: Math.round(memory.heapUsed / 1024 / 1024),
          heapTotal: Math.round(memory.heapTotal / 1024 / 1024)
        }
      }
    };
  }

  private async checkRedisStreams(): Promise<void> {
    // æ£€æŸ¥Redis Streamsè¿æ¥å’ŒåŸºæœ¬æ“ä½œ
    const testStream = 'health:check:stream:' + Date.now();
    
    try {
      // æµ‹è¯•å†™å…¥stream
      const messageId = await this.redis.xadd(testStream, '*', 'test', 'data');
      
      // æµ‹è¯•è¯»å–stream
      const messages = await this.redis.xrange(testStream, '-', '+');
      if (messages.length === 0) {
        throw new Error('Redis Streams read test failed');
      }
      
      // æ¸…ç†æµ‹è¯•æ•°æ®
      await this.redis.del(testStream);
    } catch (error) {
      throw new Error(`Redis Streams health check failed: ${error.message}`);
    }
  }

  private async checkDatabase(): Promise<void> {
    // æ£€æŸ¥PostgreSQLè¿æ¥
    await this.prisma.$queryRaw`SELECT 1`;
  }

  private async checkQueues(): Promise<void> {
    // æ£€æŸ¥æ´»è·ƒé˜Ÿåˆ—çŠ¶æ€
    const activeQueues = await this.messageQueueService.getActiveQueues();
    
    for (const queue of activeQueues) {
      try {
        const queueInfo = await this.redis.xinfo('STREAM', queue.name);
        if (!queueInfo) {
          throw new Error(`Queue ${queue.name} is not accessible`);
        }
      } catch (error) {
        throw new Error(`Queue health check failed for ${queue.name}: ${error.message}`);
      }
    }
  }

  private async checkConsumers(): Promise<void> {
    // æ£€æŸ¥æ¶ˆè´¹è€…ç»„çŠ¶æ€
    const activeConsumers = await this.messageQueueService.getActiveConsumers();
    
    // æ£€æŸ¥æ˜¯å¦æœ‰æ¶ˆè´¹è€…å¤„äºå¼‚å¸¸çŠ¶æ€
    const unhealthyConsumers = activeConsumers.filter(consumer => {
      const lastHeartbeat = new Date(consumer.lastHeartbeat);
      const now = new Date();
      const timeSinceLastHeartbeat = now.getTime() - lastHeartbeat.getTime();
      
      // å¦‚æœè¶…è¿‡60ç§’æ²¡æœ‰å¿ƒè·³ï¼Œè®¤ä¸ºæ¶ˆè´¹è€…ä¸å¥åº·
      return timeSinceLastHeartbeat > 60000;
    });

    if (unhealthyConsumers.length > 0) {
      throw new Error(`Found ${unhealthyConsumers.length} unhealthy consumers`);
    }
  }

  private async checkMemory(): Promise<void> {
    const memory = process.memoryUsage();
    const memoryUsageMB = memory.heapUsed / 1024 / 1024;
    
    // æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦è¶…è¿‡é˜ˆå€¼(400MBè­¦å‘Š)
    if (memoryUsageMB > 400) {
      throw new Error(`High memory usage: ${Math.round(memoryUsageMB)}MB`);
    }
  }

  private async checkDependencies(): Promise<void> {
    // æ£€æŸ¥å…³é”®æœåŠ¡ä¾èµ–
    const dependencies = [
      { name: 'auth-service', url: process.env.AUTH_SERVICE_URL },
      { name: 'user-service', url: process.env.USER_SERVICE_URL },
      { name: 'audit-service', url: process.env.AUDIT_SERVICE_URL },
      { name: 'notification-service', url: process.env.NOTIFICATION_SERVICE_URL }
    ];

    for (const dep of dependencies) {
      if (dep.url) {
        try {
          const response = await fetch(`${dep.url}/health`, { timeout: 3000 });
          if (!response.ok) {
            throw new Error(`${dep.name} health check failed`);
          }
        } catch (error) {
          // ä¾èµ–æœåŠ¡ä¸å¯ç”¨æ—¶åªè®°å½•è­¦å‘Šï¼Œä¸å½±å“è‡ªèº«å¥åº·çŠ¶æ€
          console.warn(`Dependency ${dep.name} is unavailable:`, error.message);
        }
      }
    }
  }

  private async getHealthMetrics(): Promise<any> {
    const metrics = await this.messageQueueService.getMetrics();
    const memory = process.memoryUsage();
    
    return {
      messageQueue: {
        totalQueues: metrics.totalQueues,
        totalMessages: metrics.totalMessages,
        pendingMessages: metrics.pendingMessages,
        processingRate: metrics.processingRate,
        errorRate: metrics.errorRate,
        averageLatency: metrics.averageLatency
      },
      consumers: {
        activeConsumers: metrics.activeConsumers,
        totalLag: metrics.totalLag
      },
      system: {
        memory: {
          used: Math.round(memory.heapUsed / 1024 / 1024),
          total: Math.round(memory.heapTotal / 1024 / 1024),
          usage: Math.round((memory.heapUsed / memory.heapTotal) * 100)
        },
        uptime: process.uptime(),
        cpu: process.cpuUsage()
      }
    };
  }

  private async getQueuesInfo(): Promise<any> {
    const queues = await this.messageQueueService.getActiveQueues();
    const queuesInfo = [];

    for (const queue of queues) {
      try {
        const streamInfo = await this.redis.xinfo('STREAM', queue.name);
        queuesInfo.push({
          name: queue.name,
          length: streamInfo.length,
          lastGeneratedId: streamInfo['last-generated-id'],
          groups: streamInfo['groups']
        });
      } catch (error) {
        queuesInfo.push({
          name: queue.name,
          status: 'error',
          error: error.message
        });
      }
    }

    return queuesInfo;
  }
}

// å¥åº·æ£€æŸ¥å“åº”æ¥å£
interface HealthCheckResponse {
  status: 'healthy' | 'unhealthy' | 'degraded';
  timestamp: string;
  service: string;
  version: string;
  uptime: number;
  responseTime: number;
  checks: {
    redisStreams: string;
    database: string;
    queues: string;
    consumers: string;
    memory: string;
    dependencies: string;
  };
  metrics: any;
}

interface MessageQueueStatusResponse {
  service: string;
  status: string;
  timestamp: string;
  redis: {
    version: string;
    uptime: number;
    connectedClients: number;
    usedMemory: string;
    totalCommandsProcessed: number;
  };
  queues: any[];
  application: {
    nodeVersion: string;
    pid: number;
    uptime: number;
    memory: {
      rss: number;
      heapUsed: number;
      heapTotal: number;
    };
  };
}
```

### å¥åº·æ£€æŸ¥ç‰¹æ€§
- **Redisè¿é€šæ€§æ£€æŸ¥**: æµ‹è¯•Redis Streamsè¯»å†™æ“ä½œ
- **æ•°æ®åº“è¿æ¥çŠ¶æ€**: éªŒè¯PostgreSQLè¿æ¥
- **é˜Ÿåˆ—çŠ¶æ€ç›‘æ§**: æ£€æŸ¥æ‰€æœ‰æ´»è·ƒé˜Ÿåˆ—çš„å¥åº·çŠ¶æ€
- **æ¶ˆè´¹è€…å¥åº·çŠ¶æ€**: ç›‘æ§æ¶ˆè´¹è€…ç»„çš„å¿ƒè·³å’Œå¤„ç†çŠ¶æ€
- **å†…å­˜ä½¿ç”¨ç›‘æ§**: é˜²æ­¢å†…å­˜æ³„æ¼å’Œè¿‡åº¦ä½¿ç”¨
- **ä¾èµ–æœåŠ¡æ£€æŸ¥**: éªŒè¯å…³é”®æœåŠ¡çš„å¯ç”¨æ€§

## ğŸ³ éƒ¨ç½²é…ç½®

### Docker Composeé…ç½®
```yaml
# docker-compose.yml
services:
  message-queue-service:
    build: ./message-queue-service
    container_name: message-queue-service
    ports:
      - "3010:3010"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://platform_user:platform_pass@postgres:5432/platform_db
      - REDIS_URL=redis://redis:6379/10
      - INTERNAL_SERVICE_TOKEN=${INTERNAL_SERVICE_TOKEN}
      - AUTH_SERVICE_URL=http://auth-service:3001
      - USER_SERVICE_URL=http://user-management-service:3003
      - AUDIT_SERVICE_URL=http://audit-service:3008
      - NOTIFICATION_SERVICE_URL=http://notification-service:3005
      - MESSAGE_BATCH_SIZE=50
      - MAX_CONCURRENT_CONSUMERS=5
      - PROCESSING_TIMEOUT_MS=15000
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
    networks:
      - platform-network
    deploy:
      resources:
        limits:
          memory: 768M
          cpus: '0.75'
        reservations:
          memory: 384M
          cpus: '0.5'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3010/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
```

### ç¯å¢ƒå˜é‡é…ç½®
```env
NODE_ENV=production
PORT=3010
DATABASE_URL=postgresql://platform_user:platform_pass@postgres:5432/platform_db
REDIS_URL=redis://redis:6379/10
REDIS_KEY_PREFIX=mq:
INTERNAL_SERVICE_TOKEN=${INTERNAL_SERVICE_TOKEN}
MAX_MESSAGE_SIZE=1048576  # 1MB
DEFAULT_TTL=604800       # 7å¤©
MAX_QUEUE_LENGTH=10000
CONSUMER_TIMEOUT=30000
METRICS_ENABLED=true
HEALTH_CHECK_INTERVAL=30
```

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•
- æ¶ˆæ¯å‘å¸ƒ/è®¢é˜…é€»è¾‘æµ‹è¯•
- Redis Streamsæ“ä½œæµ‹è¯•
- åºåˆ—åŒ–/ååºåˆ—åŒ–æµ‹è¯•
- é”™è¯¯å¤„ç†æµ‹è¯•

### é›†æˆæµ‹è¯•
- ä¸Redisé›†æˆæµ‹è¯•
- ä¸PostgreSQLé›†æˆæµ‹è¯•
- æœåŠ¡é—´é€šä¿¡æµ‹è¯•
- APIç«¯ç‚¹æµ‹è¯•

### æ€§èƒ½æµ‹è¯•
- æ¶ˆæ¯ååé‡æµ‹è¯• (ç›®æ ‡1000 QPS)
- å»¶è¿Ÿæµ‹è¯• (ç›®æ ‡P95 < 50ms)
- å¹¶å‘æ¶ˆè´¹è€…æµ‹è¯•
- å†…å­˜ä½¿ç”¨æµ‹è¯• (ç›®æ ‡512MB)

## ğŸ“… é¡¹ç›®è§„åˆ’

### å¼€å‘å‘¨æœŸ
**Week 3-4** (æ ‡å‡†ç‰ˆæœ¬4å‘¨è®¡åˆ’)
- **ä¼˜å…ˆçº§**: â­â­â­â­ (Week 3-4 æ‰©å±•æœåŠ¡)
- **å†…å­˜åˆ†é…**: 768MB (æ€»è®¡8GBä¸­çš„åˆ†é…)
- **APIç«¯ç‚¹**: 14ä¸ªæ ¸å¿ƒç«¯ç‚¹

### é‡Œç¨‹ç¢‘è®¾ç½®
- **Week 3.1**: åŸºç¡€æ¶ˆæ¯æ“ä½œå®ç° (å‘å¸ƒ/è®¢é˜…)
- **Week 3.2**: Redis Streamsé›†æˆå®Œæˆ
- **Week 3.3**: é˜Ÿåˆ—ç®¡ç†å’Œç›‘æ§åŠŸèƒ½
- **Week 3.4**: å¥åº·æ£€æŸ¥å’ŒæœåŠ¡é›†æˆ
- **Week 4.1**: æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†
- **Week 4.2**: ç»¼åˆæµ‹è¯•å’Œéƒ¨ç½²éªŒè¯

### é£é™©è¯„ä¼°
- **æŠ€æœ¯é£é™©**: Redis Streamså­¦ä¹ æ›²çº¿ - ä¸­ç­‰é£é™©
- **ä¾èµ–é£é™©**: éœ€è¦è®¤è¯æœåŠ¡å…ˆå®Œæˆ - ä½é£é™©
- **é›†æˆé£é™©**: ä¸æ‰€æœ‰æœåŠ¡éƒ½æœ‰æ¶ˆæ¯äº¤äº’ - é«˜é£é™©
- **æ€§èƒ½é£é™©**: 10ä¸‡ç”¨æˆ·æ¶ˆæ¯é‡ - ä¸­ç­‰é£é™©

## âœ… å¼€å‘å®Œæˆæƒ…å†µæ€»ç»“

### æ¶æ„è®¾è®¡é˜¶æ®µ âœ… å·²å®Œæˆ
- âœ… ç³»ç»Ÿæ¶æ„è®¾è®¡ï¼šç®€åŒ–çš„Redis Streamsæ¶æ„ï¼Œé¿å…Kafkaå¤æ‚æ€§
- âœ… æ•°æ®åº“è®¾è®¡ï¼šå®Œæ•´çš„PostgreSQLè¡¨ç»“æ„è®¾è®¡(4ä¸ªæ ¸å¿ƒè¡¨)
- âœ… APIè®¾è®¡ï¼š14ä¸ªRESTfulæ¥å£ï¼Œæ¶µç›–4ä¸ªåŠŸèƒ½æ¨¡å—
- âœ… å®‰å…¨æ¶æ„è®¾è®¡ï¼šæœåŠ¡é—´è®¤è¯ã€æ¶ˆæ¯åŠ å¯†ã€è®¿é—®æ§åˆ¶
- âœ… æ€§èƒ½è§„åˆ’ï¼šé’ˆå¯¹æ ‡å‡†ç‰ˆæœ¬è§„æ¨¡çš„æ‰¹é‡å¤„ç†å’Œè¿æ¥æ± è®¾è®¡

### æŠ€æœ¯æ¶æ„ä¼˜åŒ–
1. **ç§»é™¤è¿‡åº¦å¤æ‚æ€§**ï¼šä»Kafkaæ··åˆæ¶æ„ç®€åŒ–ä¸ºRedis Streamså•ä¸€æ¶æ„
2. **ç»Ÿä¸€åŸºç¡€è®¾æ–½**ï¼šå…±äº«PostgreSQLå’ŒRediså®ä¾‹ï¼Œé™ä½è¿ç»´å¤æ‚åº¦
3. **Docker Composeä¼˜åŒ–**ï¼šé¿å…K8Sï¼Œä½¿ç”¨å®¹å™¨ç¼–æ’è¿›è¡ŒæœåŠ¡å‘ç°

### æœåŠ¡é›†æˆå¢å¼º
1. **å†…éƒ¨APIè®¾è®¡**ï¼šå®šä¹‰ä¸å…¶ä»–11ä¸ªæœåŠ¡çš„æ¶ˆæ¯äº¤äº’æ¥å£
2. **ç»Ÿä¸€é”™è¯¯å¤„ç†**ï¼šæ ‡å‡†åŒ–é”™è¯¯å“åº”æ ¼å¼å’Œé‡è¯•æœºåˆ¶
3. **å¥åº·æ£€æŸ¥é›†æˆ**ï¼šä¸ç›‘æ§æœåŠ¡(3007)æ·±åº¦é›†æˆ

### æ ‡å‡†ç‰ˆæœ¬é€‚é…
1. **æ€§èƒ½ç›®æ ‡æ˜ç¡®**ï¼šæ—¥å¤„ç†100ä¸‡æ¶ˆæ¯ï¼Œæ”¯æŒ1000 QPS
2. **èµ„æºé…ç½®ä¼˜åŒ–**ï¼š512MBå†…å­˜åˆ†é…ï¼Œé€‚åˆ8GBæ€»å†…å­˜é™åˆ¶
3. **éƒ¨ç½²ç®€åŒ–**ï¼šå•ä¸€Docker Composeæ–‡ä»¶ï¼Œé¿å…å¤šç»„ä»¶ä¾èµ–

é€šè¿‡æ ‡å‡†ç‰ˆæœ¬ä¼˜åŒ–ï¼Œæ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡ç°åœ¨å…·å¤‡äº†ç”Ÿäº§çº§åˆ«çš„æ¶æ„è®¾è®¡ã€æ˜ç¡®çš„å¼€å‘è·¯å¾„å’Œå®Œæ•´çš„é›†æˆæ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨4å‘¨å¼€å‘è®¡åˆ’ä¸­é«˜è´¨é‡äº¤ä»˜ã€‚