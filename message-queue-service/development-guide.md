# æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡å¼€å‘æŒ‡å—

## ğŸ¯ æœåŠ¡æ¦‚è¿°

æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡æ˜¯å¾®æœåŠ¡å¹³å°çš„æ¶ˆæ¯ä¸­é—´ä»¶æ ¸å¿ƒï¼Œé¢å‘**100ç§Ÿæˆ·+10ä¸‡ç”¨æˆ·**çš„ä¼ä¸šçº§ç”Ÿäº§ç³»ç»Ÿï¼Œè´Ÿè´£å¼‚æ­¥æ¶ˆæ¯ä¼ é€’ã€æœåŠ¡è§£è€¦ã€äº‹ä»¶é©±åŠ¨æ¶æ„å’Œå¯é æ¶ˆæ¯ä¼ è¾“ï¼Œä¸ºæ•´ä¸ªå¹³å°æä¾›é«˜æ€§èƒ½ã€é«˜å¯ç”¨çš„æ¶ˆæ¯é€šä¿¡èƒ½åŠ›ã€‚

### æ ¸å¿ƒåŠŸèƒ½
- **é˜Ÿåˆ—ç®¡ç†**: åˆ›å»ºã€é…ç½®ã€ç›‘æ§æ¶ˆæ¯é˜Ÿåˆ—
- **æ¶ˆæ¯å‘å¸ƒ**: æ”¯æŒå•æ¡ã€æ‰¹é‡ã€å»¶è¿Ÿã€å®šæ—¶æ¶ˆæ¯å‘å¸ƒ
- **æ¶ˆæ¯è®¢é˜…**: çµæ´»çš„è®¢é˜…ç®¡ç†å’Œæ¶ˆè´¹è€…ç»„é…ç½®
- **ç›‘æ§ç»Ÿè®¡**: å®æ—¶æ¶ˆæ¯å¤„ç†æŒ‡æ ‡å’Œç³»ç»Ÿå¥åº·çŠ¶æ€

### æœåŠ¡å®šä½
- **ç«¯å£**: 3010
- **ä¾èµ–å…³ç³»**: ä¾èµ–ç”¨æˆ·ç®¡ç†(3003)ã€è®¤è¯æˆæƒ(3001)ã€APIç½‘å…³(3000)
- **ä¼˜å…ˆçº§**: â­â­â­â­ (Week 3-4 æ‰©å±•æœåŠ¡)
- **å¤æ‚åº¦**: é«˜ - Redis Streams + PostgreSQL

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

### æ ‡å‡†ç‰ˆæœ¬æŠ€æœ¯é€‰æ‹© âœ…
- **æ¶ˆæ¯å­˜å‚¨**: Redis Streams (é€‚åˆæ ‡å‡†ç‰ˆæœ¬ååé‡)
- **å…ƒæ•°æ®å­˜å‚¨**: PostgreSQL (å¤ç”¨ç°æœ‰æ•°æ®åº“)
- **æ¡†æ¶**: NestJS 10.x + TypeScript 5.x (ç»Ÿä¸€æŠ€æœ¯æ ˆ)
- **éƒ¨ç½²**: Docker Compose (é¿å…K8Så¤æ‚æ€§)
- **åºåˆ—åŒ–**: JSON (ç®€åŒ–å¤„ç†)

### ä¼ä¸šç‰ˆæœ¬æ‰©å±•è®¡åˆ’ â­ (V2.0ç‰ˆæœ¬)
- **é«˜çº§æ¶ˆæ¯é˜Ÿåˆ—**: ä¼ä¸šç‰ˆå¯é€‰Kafkaé›†æˆ
- **æ¶ˆæ¯å‹ç¼©**: Protobuf/Avroç­‰é«˜çº§åºåˆ—åŒ–
- **åˆ†å¸ƒå¼è·Ÿè¸ª**: Jaeger/Zipkiné›†æˆ

## ğŸ“‹ å®Œæ•´åŠŸèƒ½åˆ—è¡¨

### 1. é˜Ÿåˆ—ç®¡ç† (Queue Management)
- åˆ›å»ºé˜Ÿåˆ—/ä¸»é¢˜
- é˜Ÿåˆ—é…ç½®ç®¡ç†
- é˜Ÿåˆ—çŠ¶æ€ç›‘æ§
- é˜Ÿåˆ—æ¸…ç©ºå’Œåˆ é™¤

### 2. æ¶ˆæ¯å‘å¸ƒ (Message Publishing)
- å•æ¡æ¶ˆæ¯å‘å¸ƒ
- æ‰¹é‡æ¶ˆæ¯å‘å¸ƒ
- å»¶è¿Ÿæ¶ˆæ¯å‘å¸ƒ
- å®šæ—¶æ¶ˆæ¯å‘å¸ƒ
- æ¶ˆæ¯è·¯ç”±å’Œåˆ†åŒº

### 3. æ¶ˆæ¯è®¢é˜… (Message Subscription)
- è®¢é˜…åˆ›å»ºå’Œé…ç½®
- æ¶ˆè´¹è€…ç»„ç®¡ç†
- æ¶ˆæ¯æ¶ˆè´¹å’Œç¡®è®¤
- å¤±è´¥é‡è¯•æœºåˆ¶

### 4. ç›‘æ§ç»Ÿè®¡ (Monitoring & Metrics)
- æ¶ˆæ¯å¤„ç†æŒ‡æ ‡
- é˜Ÿåˆ—çŠ¶æ€ç›‘æ§
- æ¶ˆè´¹è€…æ€§èƒ½ç›‘æ§
- ç³»ç»Ÿå¥åº·æ£€æŸ¥

## ğŸ”— APIè®¾è®¡

### é˜Ÿåˆ—ç®¡ç†æ¥å£
```typescript
POST   /api/v1/mq/queues                     // åˆ›å»ºé˜Ÿåˆ—
GET    /api/v1/mq/queues                     // è·å–é˜Ÿåˆ—åˆ—è¡¨
GET    /api/v1/mq/queues/{name}              // è·å–é˜Ÿåˆ—è¯¦æƒ…
PUT    /api/v1/mq/queues/{name}              // æ›´æ–°é˜Ÿåˆ—é…ç½®
DELETE /api/v1/mq/queues/{name}              // åˆ é™¤é˜Ÿåˆ—
POST   /api/v1/mq/queues/{name}/purge        // æ¸…ç©ºé˜Ÿåˆ—
```

### æ¶ˆæ¯å‘å¸ƒæ¥å£
```typescript
POST   /api/v1/mq/publish                    // å‘å¸ƒå•æ¡æ¶ˆæ¯
POST   /api/v1/mq/publish/batch              // æ‰¹é‡å‘å¸ƒæ¶ˆæ¯
POST   /api/v1/mq/publish/delayed            // å»¶è¿Ÿæ¶ˆæ¯å‘å¸ƒ
POST   /api/v1/mq/publish/scheduled          // å®šæ—¶æ¶ˆæ¯å‘å¸ƒ
POST   /api/v1/mq/topics/{name}/publish      // å‘å¸ƒåˆ°æŒ‡å®šä¸»é¢˜
```

### æ¶ˆæ¯è®¢é˜…ç®¡ç†
```typescript
POST   /api/v1/mq/subscriptions              // åˆ›å»ºè®¢é˜…
GET    /api/v1/mq/subscriptions              // è·å–è®¢é˜…åˆ—è¡¨
GET    /api/v1/mq/subscriptions/{id}         // è·å–è®¢é˜…è¯¦æƒ…
PUT    /api/v1/mq/subscriptions/{id}         // æ›´æ–°è®¢é˜…
DELETE /api/v1/mq/subscriptions/{id}         // åˆ é™¤è®¢é˜…
POST   /api/v1/mq/subscriptions/{id}/pause   // æš‚åœè®¢é˜…
POST   /api/v1/mq/subscriptions/{id}/resume  // æ¢å¤è®¢é˜…
```

### ç›‘æ§ç»Ÿè®¡æ¥å£
```typescript
GET    /api/v1/mq/metrics                    // è·å–ç³»ç»ŸæŒ‡æ ‡
GET    /api/v1/mq/metrics/topics             // è·å–ä¸»é¢˜æŒ‡æ ‡
GET    /api/v1/mq/metrics/consumers          // è·å–æ¶ˆè´¹è€…æŒ‡æ ‡
GET    /api/v1/mq/health                     // å¥åº·æ£€æŸ¥
GET    /api/v1/mq/status                     // æœåŠ¡çŠ¶æ€
```

## ğŸ—„ï¸ æ•°æ®åº“è®¾è®¡

### ä¸»é¢˜è¡¨ (message_topics)
```sql
CREATE TABLE message_topics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(200) NOT NULL UNIQUE,
  display_name VARCHAR(200),
  description TEXT,
  
  -- ä¸»é¢˜é…ç½®
  topic_type VARCHAR(50) NOT NULL, -- 'kafka', 'redis_stream'
  partition_count INTEGER DEFAULT 1,
  replication_factor INTEGER DEFAULT 1,
  retention_ms BIGINT DEFAULT 604800000, -- 7å¤©
  
  -- æ¶ˆæ¯é…ç½®
  message_format VARCHAR(50) DEFAULT 'json', -- 'json', 'avro', 'protobuf'
  schema_definition JSONB,
  compression_type VARCHAR(20) DEFAULT 'none',
  
  -- è®¿é—®æ§åˆ¶
  tenant_id UUID NOT NULL,
  is_public BOOLEAN DEFAULT FALSE,
  allowed_producers JSONB DEFAULT '[]',
  allowed_consumers JSONB DEFAULT '[]',
  
  -- çŠ¶æ€ç®¡ç†
  status VARCHAR(20) DEFAULT 'active', -- 'active', 'paused', 'archived'
  
  -- æ—¶é—´æˆ³
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);
```

### è®¢é˜…è¡¨ (message_subscriptions)
```sql
CREATE TABLE message_subscriptions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  topic_id UUID REFERENCES message_topics(id) ON DELETE CASCADE,
  
  -- è®¢é˜…ä¿¡æ¯
  consumer_group VARCHAR(200) NOT NULL,
  consumer_name VARCHAR(200) NOT NULL,
  subscription_type VARCHAR(50) NOT NULL, -- 'kafka_consumer', 'redis_consumer', 'webhook'
  
  -- æ¶ˆè´¹é…ç½®
  offset_reset_policy VARCHAR(20) DEFAULT 'latest', -- 'earliest', 'latest'
  max_poll_records INTEGER DEFAULT 500,
  session_timeout_ms INTEGER DEFAULT 30000,
  heartbeat_interval_ms INTEGER DEFAULT 3000,
  
  -- æ¶ˆæ¯å¤„ç†
  handler_config JSONB NOT NULL, -- å¤„ç†å™¨é…ç½®
  dead_letter_queue VARCHAR(200),
  max_retry_attempts INTEGER DEFAULT 3,
  retry_delay_ms INTEGER DEFAULT 1000,
  
  -- è¿‡æ»¤å™¨
  message_filter JSONB, -- æ¶ˆæ¯è¿‡æ»¤æ¡ä»¶
  
  -- çŠ¶æ€ç®¡ç†
  status VARCHAR(20) DEFAULT 'active', -- 'active', 'paused', 'stopped'
  tenant_id UUID NOT NULL,
  
  -- æ—¶é—´æˆ³
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  last_consumed_at TIMESTAMP,
  
  UNIQUE(topic_id, consumer_group, consumer_name)
);
```

### æ¶ˆæ¯è®°å½•è¡¨ (message_records)
```sql
CREATE TABLE message_records (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  topic_id UUID REFERENCES message_topics(id),
  
  -- æ¶ˆæ¯æ ‡è¯†
  message_key VARCHAR(500),
  message_id VARCHAR(200) UNIQUE NOT NULL,
  correlation_id VARCHAR(200),
  
  -- æ¶ˆæ¯å†…å®¹
  headers JSONB DEFAULT '{}',
  payload JSONB,
  payload_size INTEGER,
  content_type VARCHAR(100) DEFAULT 'application/json',
  
  -- è·¯ç”±ä¿¡æ¯
  partition_id INTEGER,
  offset_value BIGINT,
  
  -- æ¶ˆæ¯çŠ¶æ€
  status VARCHAR(20) DEFAULT 'published', -- 'published', 'consumed', 'failed', 'dead_letter'
  retry_count INTEGER DEFAULT 0,
  
  -- æ—¶é—´ä¿¡æ¯
  published_at TIMESTAMP DEFAULT NOW(),
  scheduled_at TIMESTAMP,
  consumed_at TIMESTAMP,
  expires_at TIMESTAMP,
  
  -- å…ƒæ•°æ®
  producer_id VARCHAR(200),
  tenant_id UUID NOT NULL,
  trace_id VARCHAR(100)
);
```

### æ¶ˆè´¹è®°å½•è¡¨ (consumption_records)
```sql
CREATE TABLE consumption_records (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  subscription_id UUID REFERENCES message_subscriptions(id),
  message_id VARCHAR(200) NOT NULL,
  
  -- æ¶ˆè´¹ä¿¡æ¯
  consumer_instance VARCHAR(200) NOT NULL,
  partition_id INTEGER,
  offset_value BIGINT,
  
  -- å¤„ç†ç»“æœ
  status VARCHAR(20) NOT NULL, -- 'success', 'failed', 'retrying'
  processing_time_ms INTEGER,
  error_message TEXT,
  retry_count INTEGER DEFAULT 0,
  
  -- æ—¶é—´æˆ³
  consumed_at TIMESTAMP DEFAULT NOW(),
  processed_at TIMESTAMP,
  next_retry_at TIMESTAMP,
  
  -- å…ƒæ•°æ®
  tenant_id UUID NOT NULL
);
```

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„å®ç°

### æ ‡å‡†ç‰ˆæœ¬æ¶ˆæ¯æ¶æ„
**ç®€åŒ–æ¶æ„** - ä¸“æ³¨Redis Streamsï¼Œé¿å…è¿‡åº¦å¤æ‚æ€§ï¼š

```mermaid
graph TB
    Producer[æ¶ˆæ¯ç”Ÿäº§è€…] --> Gateway[APIç½‘å…³:3000]
    Gateway --> MQService[æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡:3010]
    
    MQService --> RedisStreams[Redis Streams]
    MQService --> PostgreSQL[PostgreSQLå…ƒæ•°æ®]
    
    RedisStreams --> ConsumerGroup[æ¶ˆè´¹è€…ç»„]
    ConsumerGroup --> MessageProcessor[æ¶ˆæ¯å¤„ç†å™¨]
    
    MessageProcessor --> UserService[ç”¨æˆ·æœåŠ¡:3003]
    MessageProcessor --> NotificationService[é€šçŸ¥æœåŠ¡:3005]
    MessageProcessor --> AuditService[å®¡è®¡æœåŠ¡:3008]
    
    MessageProcessor --> DeadLetter[æ­»ä¿¡é˜Ÿåˆ—]
    MessageProcessor --> Monitoring[ç›‘æ§æœåŠ¡:3007]
```

### Redis Streamså®ç°
```typescript
@Injectable()
export class MessagePublisher {
  constructor(
    private readonly redis: Redis,
    private readonly auditService: AuditService
  ) {}
  
  async publishMessage(request: PublishMessageRequest): Promise<PublishMessageResponse> {
    const stream = `mq:${request.queue}`;
    const messageData = {
      id: generateId(),
      payload: JSON.stringify(request.payload),
      headers: JSON.stringify(request.headers || {}),
      tenant_id: request.tenantId,
      created_at: Date.now().toString()
    };
    
    try {
      const messageId = await this.redis.xadd(
        stream,
        '*',
        ...Object.entries(messageData).flat()
      );
      
      await this.auditService.logOperation({
        operation: 'message_published',
        resource: `queue:${request.queue}`,
        tenantId: request.tenantId,
        details: { messageId, size: JSON.stringify(request.payload).length }
      });
      
      return {
        messageId,
        queue: request.queue,
        publishedAt: new Date()
      };
    } catch (error) {
      throw new MessagePublishException(
        `Failed to publish message to queue ${request.queue}`,
        error
      );
    }
  }
}
```

## ğŸ”„ æœåŠ¡é—´äº¤äº’è®¾è®¡

### å†…éƒ¨APIæ¥å£ (æœåŠ¡é—´é€šä¿¡)
```typescript
// å†…éƒ¨æœåŠ¡è°ƒç”¨ - ä½¿ç”¨X-Service-Tokenè®¤è¯
interface InternalMessageAPI {
  // ç”¨æˆ·æœåŠ¡è°ƒç”¨
  'POST /internal/mq/user-events',           // ç”¨æˆ·äº‹ä»¶å‘å¸ƒ
  'POST /internal/mq/user-notifications',   // ç”¨æˆ·é€šçŸ¥æ¶ˆæ¯
  
  // å®¡è®¡æœåŠ¡è°ƒç”¨
  'POST /internal/mq/audit-logs',           // å®¡è®¡æ—¥å¿—æ¶ˆæ¯
  'GET /internal/mq/audit-queue-status',    // å®¡è®¡é˜Ÿåˆ—çŠ¶æ€
  
  // é€šçŸ¥æœåŠ¡è°ƒç”¨
  'POST /internal/mq/notifications',        // é€šçŸ¥æ¶ˆæ¯å‘å¸ƒ
  'GET /internal/mq/notification-queue',    // é€šçŸ¥é˜Ÿåˆ—çŠ¶æ€
  
  // ç›‘æ§æœåŠ¡è°ƒç”¨
  'GET /internal/mq/metrics',              // æ¶ˆæ¯é˜Ÿåˆ—æŒ‡æ ‡
  'GET /internal/mq/health-detailed'       // è¯¦ç»†å¥åº·çŠ¶æ€
}
```

### ç»Ÿä¸€é”™è¯¯å¤„ç†
```typescript
// æ ‡å‡†ç‰ˆæœ¬é”™è¯¯å“åº”æ ¼å¼
interface MessageQueueError {
  code: 'MQ_QUEUE_NOT_FOUND' | 'MQ_PUBLISH_FAILED' | 'MQ_CONSUMER_ERROR';
  message: string;
  details?: any;
  retryAfter?: number; // é‡è¯•å»¶è¿Ÿ(ç§’)
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### æ‰¹é‡å¤„ç†ä¼˜åŒ–
```typescript
@Injectable()
export class BatchProcessor {
  private batches: Map<string, MessageBatch> = new Map();
  
  async addToBatch(topic: string, message: Message): Promise<void> {
    let batch = this.batches.get(topic);
    
    if (!batch) {
      batch = new MessageBatch(topic, this.config.batchSize);
      this.batches.set(topic, batch);
    }
    
    batch.addMessage(message);
    
    if (batch.isFull() || batch.isExpired()) {
      await this.processBatch(batch);
      this.batches.delete(topic);
    }
  }
}
```

### è¿æ¥æ± ç®¡ç†
- Redisè¿æ¥æ± ï¼š5-20ä¸ªè¿æ¥
- æ¶ˆæ¯æ‰¹é‡å¤§å°ï¼š50æ¡/æ‰¹æ¬¡
- æœ€å¤§å¹¶å‘æ¶ˆè´¹è€…ï¼š5ä¸ª
- å¤„ç†è¶…æ—¶ï¼š15ç§’

## ğŸ›¡ï¸ å®‰å…¨æªæ–½

### æ¶ˆæ¯åŠ å¯†
```typescript
@Injectable()
export class MessageEncryption {
  async encryptMessage(payload: any, tenantKey: string): Promise<string> {
    const cipher = crypto.createCipher('aes-256-gcm', tenantKey);
    const encrypted = cipher.update(JSON.stringify(payload), 'utf8', 'hex') + 
                     cipher.final('hex');
    const authTag = cipher.getAuthTag();
    
    return Buffer.from(JSON.stringify({
      data: encrypted,
      authTag: authTag.toString('hex')
    })).toString('base64');
  }
}
```

### è®¿é—®æ§åˆ¶
- ç§Ÿæˆ·çº§åˆ«æ¶ˆæ¯éš”ç¦»
- ç”Ÿäº§è€…/æ¶ˆè´¹è€…æƒé™éªŒè¯
- å†…éƒ¨æœåŠ¡é—´APIè®¤è¯
- æ¶ˆæ¯ä¼ è¾“åŠ å¯†

## ğŸ“ˆ ç›‘æ§å’Œå‘Šè­¦

### ç³»ç»ŸæŒ‡æ ‡
```typescript
interface MessageQueueMetrics {
  redisStreams: {
    totalStreams: number;
    totalConsumerGroups: number;
    totalMessages: number;
    pendingMessages: number;
  };
  
  consumers: {
    activeConsumers: number;
    totalLag: number;
    processingRate: number;
    errorRate: number;
  };
  
  performance: {
    averageLatency: number;
    p95Latency: number;
    p99Latency: number;
    throughput: number;
  };
}
```

### å¥åº·æ£€æŸ¥
- Redisè¿é€šæ€§æ£€æŸ¥
- æ•°æ®åº“è¿æ¥çŠ¶æ€
- é˜Ÿåˆ—çŠ¶æ€ç›‘æ§
- æ¶ˆè´¹è€…å¥åº·çŠ¶æ€

## ğŸ³ éƒ¨ç½²é…ç½®

### Docker Composeé…ç½®
```yaml
# docker-compose.yml
services:
  message-queue-service:
    build: ./message-queue-service
    ports:
      - "3010:3010"
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/platform
      - REDIS_URL=redis://redis:6379/5
      - AUTH_SERVICE_URL=http://auth-service:3001
      - USER_SERVICE_URL=http://user-management-service:3003
      - AUDIT_SERVICE_URL=http://audit-service:3008
      - NOTIFICATION_SERVICE_URL=http://notification-service:3005
      - MESSAGE_BATCH_SIZE=50
      - MAX_CONCURRENT_CONSUMERS=5
      - PROCESSING_TIMEOUT_MS=15000
    depends_on:
      - postgres
      - redis
      - auth-service
    networks:
      - platform-network
```

### ç¯å¢ƒå˜é‡é…ç½®
```env
NODE_ENV=production
PORT=3010
DATABASE_URL=postgresql://postgres:password@postgres:5432/platform
REDIS_URL=redis://redis:6379/5
REDIS_KEY_PREFIX=mq:
INTERNAL_SERVICE_TOKEN=your-internal-service-token
MAX_MESSAGE_SIZE=1048576  # 1MB
DEFAULT_TTL=604800       # 7å¤©
MAX_QUEUE_LENGTH=10000
CONSUMER_TIMEOUT=30000
METRICS_ENABLED=true
HEALTH_CHECK_INTERVAL=30
```

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•
- æ¶ˆæ¯å‘å¸ƒ/è®¢é˜…é€»è¾‘æµ‹è¯•
- Redis Streamsæ“ä½œæµ‹è¯•
- åºåˆ—åŒ–/ååºåˆ—åŒ–æµ‹è¯•
- é”™è¯¯å¤„ç†æµ‹è¯•

### é›†æˆæµ‹è¯•
- ä¸Redisé›†æˆæµ‹è¯•
- ä¸PostgreSQLé›†æˆæµ‹è¯•
- æœåŠ¡é—´é€šä¿¡æµ‹è¯•
- APIç«¯ç‚¹æµ‹è¯•

### æ€§èƒ½æµ‹è¯•
- æ¶ˆæ¯ååé‡æµ‹è¯• (ç›®æ ‡1000 QPS)
- å»¶è¿Ÿæµ‹è¯• (ç›®æ ‡P95 < 50ms)
- å¹¶å‘æ¶ˆè´¹è€…æµ‹è¯•
- å†…å­˜ä½¿ç”¨æµ‹è¯• (ç›®æ ‡512MB)

## ğŸ“… é¡¹ç›®è§„åˆ’

### å¼€å‘å‘¨æœŸ
**Week 3-4** (æ ‡å‡†ç‰ˆæœ¬4å‘¨è®¡åˆ’)
- **ä¼˜å…ˆçº§**: â­â­â­â­ (Week 3-4 æ‰©å±•æœåŠ¡)
- **å†…å­˜åˆ†é…**: 512MB (æ€»è®¡8GBä¸­çš„åˆ†é…)
- **APIç«¯ç‚¹**: 14ä¸ªæ ¸å¿ƒç«¯ç‚¹

### é‡Œç¨‹ç¢‘è®¾ç½®
- **Week 3.1**: åŸºç¡€æ¶ˆæ¯æ“ä½œå®ç° (å‘å¸ƒ/è®¢é˜…)
- **Week 3.2**: Redis Streamsé›†æˆå®Œæˆ
- **Week 3.3**: é˜Ÿåˆ—ç®¡ç†å’Œç›‘æ§åŠŸèƒ½
- **Week 3.4**: å¥åº·æ£€æŸ¥å’ŒæœåŠ¡é›†æˆ
- **Week 4.1**: æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†
- **Week 4.2**: ç»¼åˆæµ‹è¯•å’Œéƒ¨ç½²éªŒè¯

### é£é™©è¯„ä¼°
- **æŠ€æœ¯é£é™©**: Redis Streamså­¦ä¹ æ›²çº¿ - ä¸­ç­‰é£é™©
- **ä¾èµ–é£é™©**: éœ€è¦è®¤è¯æœåŠ¡å…ˆå®Œæˆ - ä½é£é™©
- **é›†æˆé£é™©**: ä¸æ‰€æœ‰æœåŠ¡éƒ½æœ‰æ¶ˆæ¯äº¤äº’ - é«˜é£é™©
- **æ€§èƒ½é£é™©**: 10ä¸‡ç”¨æˆ·æ¶ˆæ¯é‡ - ä¸­ç­‰é£é™©

## âœ… å¼€å‘å®Œæˆæƒ…å†µæ€»ç»“

### æ¶æ„è®¾è®¡é˜¶æ®µ âœ… å·²å®Œæˆ
- âœ… ç³»ç»Ÿæ¶æ„è®¾è®¡ï¼šç®€åŒ–çš„Redis Streamsæ¶æ„ï¼Œé¿å…Kafkaå¤æ‚æ€§
- âœ… æ•°æ®åº“è®¾è®¡ï¼šå®Œæ•´çš„PostgreSQLè¡¨ç»“æ„è®¾è®¡(4ä¸ªæ ¸å¿ƒè¡¨)
- âœ… APIè®¾è®¡ï¼š14ä¸ªRESTfulæ¥å£ï¼Œæ¶µç›–4ä¸ªåŠŸèƒ½æ¨¡å—
- âœ… å®‰å…¨æ¶æ„è®¾è®¡ï¼šæœåŠ¡é—´è®¤è¯ã€æ¶ˆæ¯åŠ å¯†ã€è®¿é—®æ§åˆ¶
- âœ… æ€§èƒ½è§„åˆ’ï¼šé’ˆå¯¹æ ‡å‡†ç‰ˆæœ¬è§„æ¨¡çš„æ‰¹é‡å¤„ç†å’Œè¿æ¥æ± è®¾è®¡

### æŠ€æœ¯æ¶æ„ä¼˜åŒ–
1. **ç§»é™¤è¿‡åº¦å¤æ‚æ€§**ï¼šä»Kafkaæ··åˆæ¶æ„ç®€åŒ–ä¸ºRedis Streamså•ä¸€æ¶æ„
2. **ç»Ÿä¸€åŸºç¡€è®¾æ–½**ï¼šå…±äº«PostgreSQLå’ŒRediså®ä¾‹ï¼Œé™ä½è¿ç»´å¤æ‚åº¦
3. **Docker Composeä¼˜åŒ–**ï¼šé¿å…K8Sï¼Œä½¿ç”¨å®¹å™¨ç¼–æ’è¿›è¡ŒæœåŠ¡å‘ç°

### æœåŠ¡é›†æˆå¢å¼º
1. **å†…éƒ¨APIè®¾è®¡**ï¼šå®šä¹‰ä¸å…¶ä»–11ä¸ªæœåŠ¡çš„æ¶ˆæ¯äº¤äº’æ¥å£
2. **ç»Ÿä¸€é”™è¯¯å¤„ç†**ï¼šæ ‡å‡†åŒ–é”™è¯¯å“åº”æ ¼å¼å’Œé‡è¯•æœºåˆ¶
3. **å¥åº·æ£€æŸ¥é›†æˆ**ï¼šä¸ç›‘æ§æœåŠ¡(3007)æ·±åº¦é›†æˆ

### æ ‡å‡†ç‰ˆæœ¬é€‚é…
1. **æ€§èƒ½ç›®æ ‡æ˜ç¡®**ï¼šæ—¥å¤„ç†100ä¸‡æ¶ˆæ¯ï¼Œæ”¯æŒ1000 QPS
2. **èµ„æºé…ç½®ä¼˜åŒ–**ï¼š512MBå†…å­˜åˆ†é…ï¼Œé€‚åˆ8GBæ€»å†…å­˜é™åˆ¶
3. **éƒ¨ç½²ç®€åŒ–**ï¼šå•ä¸€Docker Composeæ–‡ä»¶ï¼Œé¿å…å¤šç»„ä»¶ä¾èµ–

é€šè¿‡æ ‡å‡†ç‰ˆæœ¬ä¼˜åŒ–ï¼Œæ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡ç°åœ¨å…·å¤‡äº†ç”Ÿäº§çº§åˆ«çš„æ¶æ„è®¾è®¡ã€æ˜ç¡®çš„å¼€å‘è·¯å¾„å’Œå®Œæ•´çš„é›†æˆæ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨4å‘¨å¼€å‘è®¡åˆ’ä¸­é«˜è´¨é‡äº¤ä»˜ã€‚